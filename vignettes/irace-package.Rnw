%%% DO NOT EDIT the .tex file directly since it is generated from the .Rnw
%%% sources.
\RequirePackage[dvipsnames]{xcolor}
\documentclass[a4paper,english]{article}
\usepackage[a4paper]{geometry}
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{irace package:user guide}
%\VignetteDepends{knitr}
%\VignetteCompiler{knitr}
%\VignetteEngine{knitr::knitr}
\usepackage{calc}
\usepackage{algorithm,algorithmic}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{xspace}
\usepackage{amsmath,amssymb}
\usepackage{relsize}
\usepackage{fancyvrb}
\usepackage[hyphens]{url}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\usepackage[titletoc, title]{appendix}
\usepackage{tocloft}
\setlength{\cftsubsecnumwidth}{3em}% Set length of number width in ToC for \subsection
\usepackage{enumitem}
%\usepackage{listings} % for wrapping

%listing <- function(x, options) {
%    paste("\\begin{lstlisting}[basicstyle=\\ttfamily,breaklines=false]\n",
%      x, "\\end{lstlisting}\n", sep = "")
%  }
%  knit_hooks$set(source=listing, output=listing)

\DefineVerbatimEnvironment{Code}{Verbatim}{}
\DefineVerbatimEnvironment{CodeInput}{Verbatim}{fontshape=sl}
\DefineVerbatimEnvironment{CodeOutput}{Verbatim}{}

\providecommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}

%% MANUEL: What is this?
\makeatletter
\newcommand\code{\bgroup\@makeother\_\@makeother\~\@makeother\$\@codex}
\def\@codex#1{{\normalfont\ttfamily\hyphenchar\font=-1 #1}\egroup}
\makeatother

\let\proglang=\textsf
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
\newcommand{\aR}{\proglang{R}\xspace}
\newcommand{\eg}{e.g.}
\newcommand{\SoftwarePackage}{\pkg}
\newcommand{\ACOTSP}{\SoftwarePackage{ACOTSP}\xspace}

%% How to use the command:
% Parameter with one short switch: \defparameter[short]{paramName}{long}{default}
% Parameter without short switch:  \defparameter{paramName}{long}{default}
% Parameter without switch:  \defparameter{paramName}{}{default}
\newcommand{\defparameter}[4][]{%
\item[\code{#2}]\hypertarget{opt:#2}{} ~~ %
\ifthenelse{\equal{#3}{}}{}{%
  flag: %
  \ifthenelse{\equal{#1}{}}{}{%
    \code{#1} or }%
  \code{#3} ~~ }%
default:~\texttt{#4} \\
}
\newcommand{\parameter}[1]{\hyperlink{opt:#1}{\code{#1}}}


\newcommand{\irace}{\pkg{irace}\xspace}
\newcommand{\race}{\pkg{race}\xspace}
\newcommand{\FRACE}{\text{F-Race}\xspace}
\newcommand{\IFRACE}{\text{I/F-Race}\xspace}
\newcommand{\iraceversion}{2.0}

\newcommand{\Niter}{\ensuremath{N^\text{iter}}\xspace}
\newcommand{\Nparam}{\ensuremath{{N^\text{param}}}\xspace}
\newcommand{\iter}{\ensuremath{j}\xspace}
\newcommand{\Budget}{\ensuremath{B}\xspace}
\newcommand{\Budgetj}{\ensuremath{\Budget_{\iter}}\xspace}
\newcommand{\Bused}{\ensuremath{\Budget_\text{used}}\xspace}
\newcommand{\Ncand}[1][]{\ensuremath{N_{#1}}\xspace}
\newcommand{\Mui}{\ensuremath{\mu_{\iter}}\xspace}
\newcommand{\Nmin}{\ensuremath{N^\text{min}}\xspace}
\newcommand{\Nsurv}{\ensuremath{N^\text{surv}}\xspace}
\newcommand{\Nelite}{\ensuremath{N^\text{elite}}\xspace}
\newcommand{\Nnew}{\ensuremath{N^\text{new}}\xspace}


\newcommand{\MANUEL}[1]{{\footnotesize\noindent\textbf{[~MANUEL: #1~]}}}
\newcommand{\LESLIE}[1]{\footnote{\noindent\textbf{[ LESLIE: #1 ]}}}
\newcommand{\THOMAS}[1]{\footnote{\noindent\textbf{[ THOMAS: #1 ]}}}


\usepackage{tcolorbox}
\newcommand{\infoicon}{%
\parbox[c]{0.75cm}{\includegraphics[keepaspectratio=true,width=0.75cm]{light-bulb-icon}}%
\hspace{1em}}
\newcommand{\warningicon}{%
\parbox[c]{0.75cm}{\includegraphics[keepaspectratio=true,width=0.75cm]{Warning-icon}}%
\hspace{1em}}

\definecolor{LightGray}{RGB}{193,193,193}
\definecolor{LightYellow}{RGB}{253,247,172}

\newlength\macroiconwidth
\newenvironment{xwarningbox}{%
\setlength{\fboxrule}{3.0\fboxrule}%
\setlength{\fboxsep}{0\fboxsep}%
\begin{tcolorbox}[colback=LightYellow,colframe=LightGray,boxrule=\fboxrule,boxsep=\fboxsep]%
\infoicon%
\settowidth{\macroiconwidth}{\infoicon}%
\begin{minipage}[c]{\columnwidth - \macroiconwidth - 2.0\fboxrule - 2.0\fboxsep}
\raggedright\footnotesize
%
}{%
\end{minipage}
\end{tcolorbox}
%
}

\begin{document}

<<include=FALSE>>=
library(knitr)
@

\author{Manuel L\'opez-Ib\'a\~nez, Leslie P\'erez C\'aceres, J\'er\'emie Dubois-Lacoste,\\
  Thomas St\"utzle and Mauro Birattari
\\IRIDIA, CoDE, Universit\'e Libre de Bruxelles, Brussels, Belgium}

\title{The \irace Package:\\ User Guide}

%\keywords{automatic
%  algorithm configuration, racing, parameter tuning, \aR}

\maketitle

\tableofcontents

%Load files needed for examples
<<exampleload,eval=TRUE,include=FALSE>>=
library("irace")
load("examples.Rdata")
load("irace-output.Rdata")
options(width=60)
@ 
\newpage

%%
%%
%%
%% General info
%%
%%
%%
\section{General information}
\subsection{Background}
%\MANUEL{I would add a paragraph defining what is irace (a bit longer than the abstract above) and references to the literature so people can find more info. The first reference should be the irace TR.} \LESLIE{Here i guess we should say why tune an algorithm is a good idea, and why using irace is a better one.}
The \irace package implements the \emph{iterated racing} procedure, 
which is an extension of Iterated F-race (\IFRACE).  The main use of 
\irace is the automatic configuration of optimization algorithms, 
that is, finding the most appropriate settings of an optimization 
algorithm given a set of instances of an optimization problem. It 
builds upon the \pkg{race} package by Birattari and it is implemented 
in \aR. The \irace 
package is available from CRAN. More information about \irace is 
available at \url{http://iridia.ulb.ac.be/irace}.

\subsection{Version}
The current version of the \irace package is version \iraceversion. Previous 
versions of the package can be found in the \irace package CRAN website.
\begin{center}
\url{https://cran.r-project.org/web/packages/irace/}
\end{center}
%
\begin{xwarningbox}
Previous versions of \irace might not be compatible with the 
file formats detailed in this document.
\end{xwarningbox}


\subsection{License}

The \pkg{irace} package is Copyright (C) 2016 and distributed under the GNU General Public 
License version 3.0 (\url{http://www.gnu.org/licenses/gpl-3.0.en.html}).
The \irace package is free software (software libre): you can redistribute it and/or modify it under the terms 
of the GNU General Public License as published by the Free Software Foundation, 
either version 3 of the License, or (at your option) any later version.

The \irace package is distributed in the hope that it will be useful, but
WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.


\section{Before starting}
\MANUEL{I think this could be a bit more detailed by defining what is a parameter, a configuration, an instance, etc. but ok for now.}

The \irace package provides an automatic configuration tool for 
 tuning optimization algorithms. The \irace tool automatically finds good configurations for the parameters values 
of a (target) algorithm saving the effort that normally requires manual 
tuning.  

Figure~\ref{fig:irace-scheme} gives a general scheme of how \irace works.
\irace receives as input a \emph{parameter space definition} corresponding to the 
parameters of the target algorithm that will be tuned, a set of \emph{instances} 
for which the parameters must be tuned for and a set of \emph{options} for \irace.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.6\textwidth]{irace-scheme}
  \caption{Scheme of \irace flow of information.}
\label{fig:irace-scheme}
\end{figure}

\irace searches in the parameter search space for good performing algorithm
configurations by executing the target algorithm on different instances and
with different parameter configurations. To execute the target algorithm with a
specific parameter configuration ($\theta$) and instance ($i$)
a \parameter{targetRunner} must be provided. The \parameter{targetRunner} acts
as an interface between the execution of the target algorithm and \irace: It
receives the instance and configuration as arguments and must return the
evaluation of the execution of the target algorithm.

The following user guide contains  guidelines to use \irace and define the
needed components to execute \irace to automatically configure an optimization
algorithm.

%%
%%
%%
%% Installation
%%
%%
%%

\section{Installation}

\subsection{System requirements}
\begin{itemize}
\item \aR ($\text{version} \geq 2.15.0$) is required for running irace, but you don't
  need to know the \aR language to use it.  \aR is freely available and you can
  download it from the \aR project website
  (\url{http://www.r-project.org}). See Section~\ref{sec:installation} for a
  quick installation guide of \aR.

 \item For GNU/Linux and OSX, the command-line executables \code{irace} and
   \code{parallel-irace} require GNU Bash.
\end{itemize}
   
\subsection{\irace installation} \label{sec:irace install}

The \irace package can be installed automatically within \aR or 
by manual download and installation. We advise to use the automatic 
installation unless particular circumstances do not allow it. The instructions
to install \irace with the two mentioned methods are the following:
 
\subsubsection[Install automatically within R]{Install automatically within \aR{}}

In the \aR console execute the following line to install the package :
<<R_irace_install, prompt=TRUE, eval=FALSE>>=
install.packages("irace")
@
Select a mirror close to your location, and test the installation in the \aR console with:
<<R_irace_launch,eval=FALSE, prompt=TRUE>>=
library("irace")
CTRL+d
@

Alternatively, within the \aR graphical interface, you may use  
the \code{Packages and data -> Package installer} menu on OSX or the \code{Packages} menu on Windows.

\subsubsection{Manual download and installation}

From the \irace package CRAN website
(\url{http://cran.r-project.org/package=irace}), download one of the three
versions available depending of your operating system:
\begin{itemize}
\item \code{irace_\iraceversion.tar.gz} (Unix/BSD/GNU/Linux)
\item \code{irace_\iraceversion.tgz} (OSX)
\item \code{irace_\iraceversion.zip} (Windows)
\end{itemize}

To install the package on GNU/Linux and OSX, you must execute the following
command at the shell:
%
<<bash_irace_install,engine='bash',eval=FALSE>>=
# Replace <package> with the path of the downloaded file.
R CMD INSTALL <package>
@

To install the package on Windows open \aR and execute the following line on 
the \aR console:
%\LESLIE{Check that this actually works on internet says that  this: \code{Rscript -e "install.packages('foo.zip', repos = NULL)"} also works}

<<install_win1,eval=FALSE, prompt=TRUE>>=
# Replace <package> with the path of the downloaded file.
install.packages("<package>", repos = NULL)
@

If the previous installation instructions fail because of insufficient
permissions and you do not have sufficient admin rights to install \irace
system-wide, then you need to force a local installation.

\subsubsection{Local installation}

Let's assume you wish to install \irace on a path denoted by
\code{<R_LIBS_USER>}, which is a filesystem path for which you have sufficient
rights. This directory \textbf{must} exist before attempting the
installation. Moreover, you must provide to \aR the path to this
library when loading the package. However, the latter can be avoided by adding
the path to the system variable \code{R_LIBS} or to the \aR internal variable
\code{.libPaths}, as we will see below.\footnote{%
   On Windows, see also
   \url{https://cran.r-project.org/bin/windows/base/rw-FAQ.html\#I-don_0027t-have-permission-to-write-to-the-R_002d3_002e3_002e1_005clibrary-directory}.}


On GNU/Linux or OSX, execute the following commands to install the 
package on a local directory:

<<R_irace_install2,engine='bash',eval=FALSE>>=
export R_LIBS_USER="<R_LIBS_USER>"
# Create R_LIBS_USER if it doesn't exist
mkdir $R_LIBS_USER
# Replace <package> with the path to the downloaded file.
R CMD INSTALL --library=$R_LIBS_USER <package>
# Tell R where to find R_LIBS_USER        
export R_LIBS=${R_LIBS_USER}:${R_LIBS}
@

On Windows, you can install the package on a local directory by executing the
following lines in the \aR console:

<<install_win2,eval=FALSE, prompt=TRUE>>=
# Replace <package> with the path to the downloaded file.
# Replace <R_LIBS_USER>' with the path used for installation.
install.packages("<package>", repos = NULL, lib="<R_LIBS_USER>")
# Tell R where to find R_LIBS_USER.
# This must be executed for every new session.
.libPaths(c("<R_LIBS_USER>", .libPaths()))
@

\subsubsection{Testing the installation and invoking irace}

Once \irace has been installed, load the package and test that the installation 
was successful by opening an \aR console and executing:

<<R_irace_test1, prompt=TRUE, eval=FALSE>>= 
# Load the package
library("irace")
# Obtain the installation path
system.file(package="irace")
@

The last command must print out the filesystem path  where \irace is
installed.  In the remainder of this guide, the variable
\code{\$IRACE_HOME} is used to denote this path. When executing any provided
command that includes the \code{\$IRACE_HOME} variable do not forget to replace
this variable with the installation path of \irace. 

On GNU/Linux or OSX, you can let the operating system know where to find \irace
by defining the \code{\$IRACE_HOME} variable and adding it to the system
\code{PATH}. Append the following commands to \path{~/.bash_profile}, \path{~/.bashrc} or
\path{~/.profile}:
%
<<linux_irace_path1,engine='bash',eval=FALSE>>=
# Replace <IRACE_HOME> with the irace installation path 
export IRACE_HOME=<IRACE_HOME> 
export PATH=${IRACE_HOME}/bin/:$PATH
# Tell R where to find R_LIBS_USER
# Use the following line only if local installation was forced
export R_LIBS=${R_LIBS_USER}:${R_LIBS}
@

Then, open new terminal and launch \irace as follows:

<<linux_irace_help,engine='bash',eval=FALSE>>=
irace --help
@

On Windows, you need to add both \aR and the installation path of \irace to the
environment variable \code{PATH}. To edit the \code{PATH}, search for
``Environment variables'' in the control panel, then edit \code{PATH}, then add
a string similar to \path{C:\R_PATH\bin;C:\IRACE_HOME\bin}, where \code{R_PATH}
is the installation path of \aR and \code{IRACE_HOME} is the installation path
of \irace. If \irace was installed locally, you also need to edit the
environment variable \code{R_LIBS} to add \code{R_LIBS_USER}. Then, open a new
terminal (run program \code{cmd.exe}) and launch \irace as:
%
<<win_irace_help,engine='bash',eval=FALSE>>=
irace.bat --help
@

Alternatively, you may directly invoke \irace from within the \aR 
console by executing:
<<windows_irace_help ,eval=FALSE, prompt=TRUE>>=
library("irace")
irace.cmdline("--help")
@


\section{Running irace}\label{sec:execution}

Before performing the tuning of your algorithm it is necessary to define an \irace 
tuning scenario that will give \irace all the necessary information to optimize the 
parameters of the algorithm. The tuning scenario is composed of the following elements:

\begin{enumerate}
\item Target algorithm parameter description (see Section~\ref{sec:target parameters}).
\item Target algorithm runner (see Section~\ref{sec:runner}).
\item Training instances list (see Section~\ref{sec:training})
\item Irace options (see Section~\ref{sec:irace options}).
\item \textit{Optional:} Initial configurations (see Section~\ref{sec:initial}).
\item \textit{Optional:} Forbidden configurations (see Section~\ref{sec:forbidden}).
\item \textit{Optional:} Target algorithm evaluator (see Section~\ref{sec:evaluator}).
\end{enumerate}

These scenario elements can be provided as plain text files 
or as \aR objects. This user guide provides examples of both modalities,
but we advise the use of plain text files which we consider the simpler
option. 

For a step by step guide to create the scenario elements for your target algorithm 
continue to Section~\ref{sec:step}. For an example execution of \irace using the 
\ACOTSP scenario go to Section~\ref{sec:example}.  

Once all the scenario elements are prepared you can execute \irace. \irace can 
be executed using the command-line wrappers provided by the package 
(only available for GNU/Linux and OS X) or directly from the \aR console:


\begin{enumerate}
\item On GNU/Linux and OSX execute \irace by doing:

<<irace_cmd_exe0,engine='bash', eval=FALSE>>=
# $IRACE_HOME is the installation directory of irace.
$IRACE_HOME/bin/irace --scenario scenario.txt
@

For this example we assume that the needed scenario files have been set
properly in the \code{scenario.txt} file using the options described in 
Section~\ref{sec:irace options}. Most \irace options can be specified 
in the command line or directly in the \code{scenario.txt} file.  

\item On any operating system you can execute \irace from the \aR 
console by executing:

<<irace_R_exe0, eval=FALSE, prompt=TRUE>>=
library("irace")
parameters <- readParameters("parameters.txt")
scenario <- readScenario(filename="scenario.txt", 
                         scenario=defaultScenario())
irace(scenario=scenario, parameters=parameters)
@

\end{enumerate}

\irace provides a check tool to test that the scenario elements are
correctly defined. We recommend to perform a check every time
you create a new scenario. When performing the check, \irace will 
control that the scenario and parameter definition are correct and 
will test the execution of the target algorithm. To check your scenario
execute the following commands:


\begin{enumerate}
\item On GNU/Linux and OSX execute from the command-line:

<<irace_check,engine='bash', eval=FALSE>>=
# $IRACE_HOME is the installation directory of irace.
$IRACE_HOME/bin/irace --scenario scenario.txt --check
@

\item On any operating system execute from the \aR console the 
following lines:

<<irace_R_check, eval=FALSE, prompt=TRUE>>=
library("irace")
scenario <- readScenario(filename="scenario.txt",
                         scenario=defaultScenario())
checkIraceScenario(scenario=scenario)
@

\end{enumerate}

\subsection{Step by step setup guide}\label{sec:step}
This section provides a guide to setup a basic execution of \irace. The template
files provided in the package (\code{$IRACE_HOME/templates}) will be used as 
base for creating your new scenario. Please follow carefully the indications 
provided in each step and in the template files used, if you have doubts check the 
the sections that describe each scenario element in detail.
  
\begin{enumerate}
\item Create a directory (\eg~\code{~/tuning/}) for the scenario setup, this directory will contain
all the files that describe the scenario.
<<dir1,engine='bash',eval=FALSE>>=
mkdir ~/tuning
cd ~/tuning
@
To set the working directory in \aR use the following lines in the \aR console:
<<dirR1,prompt=TRUE, eval=FALSE>>=
set.wd("~/tuning")
@
\item Copy all the template files in the to the \code{$IRACE_HOME/templates/} 
directory to the scenario directory.
<<copy1,engine='bash',eval=FALSE>>=
# $IRACE_HOME is the installation directory of irace.
cp $IRACE_HOME/templates/*.tmpl  ~/tuning/
@

Remember that \code{$IRACE_HOME} is the path to the installation 
directory of \irace. It can be obtained in the \aR console with:

<<irace_path,eval=FALSE, prompt=TRUE>>=
library("irace")
system.file(package="irace")
@

\item For each template in your tuning directory, remove the \code{.tmpl} 
    suffix, and modify them following the next steps.
    %\begin{enumerate}[leftmargin=0cm]
\item Define the target algorithm parameters to be tuned, follow the 
instructions in \code{parameters.txt}.  Available parameter types and other 
guidelines can be found in Section~\ref{sec:target parameters}.
        
\item \textit{Optional}: Define forbidden parameter values combinations,
that is, configurations that \irace must not consider in the tuning. 
Follow the instructions in \code{forbidden.txt}. More information about 
forbidden configurations in Section~\ref{sec:forbidden}. \textbf{Important}: 
If you do not need to define forbidden configurations remove this file from 
the directory.
        
\item \textit{Optional}: Define the initial parameter configuration(s) of your 
algorithm, this option allows you to provide good starting configurations (if you know 
some) for the tuning. Follow the instructions in \code{configurations.txt}. More 
information in Section~\ref{sec:initial}. \textbf{Important}: If you do not need to 
define initial configurations remove this file from the directory.
     
\item Put the instances you would like to use for the tuning of your algorithm in 
the folder \code{~/tuning/Instances/}. In addition,  you can create a file 
(\eg~\code{instances-list.tmpl}) that specifies which instances from that directory
should be run and which instance-specific parameters to use. If you will be using 
the instance list file, set in the \code{scenario.txt} file as:
\begin{center}
 \code{trainInstancesFile = "instances-list.txt"} 
 \end{center}
See Section~\ref{sec:training} for guidelines.

\item Uncomment and assign in \code{scenario.txt} only the options for which you 
need a value different than the default. The names of the template files match 
the default names of the scenario options. Some common parameters that you might  
want to adjust are:
\begin{itemize}
\item \parameter{execDir} (\code{--exec-dir}): set a directory in which \irace will execute the
target algorithm, the default value is the current directory.
\item \parameter{logFile} (\code{--log-file}): set the name of the results \aR data file that produces 
\irace.
\item \parameter{maxExperiments} (\code{--max-experiments}): set the maximum number of executions 
of the target algorithm that \irace is allowed. The default is $1000$. 
\end{itemize}
For more information of \irace options and their default values see Section~\ref{sec:irace options}.

\item Modify the \code{target-runner} script to run your algorithm, this script must
execute your algorithm with the parameters and instances specified by \irace and
return \textbf{only} one number corresponding to the evaluation of the execution.
The template we use in this guide is in bash, that means it can only be used 
in GNU/Linux and OSX systems, for other systems you can use any other scripting 
language, we provide a python template in the \code{$IRACE_HOME/examples/python} 
package directory. Follow this instructions to adjust the \code{target-runner} to your algorithm:
        \begin{enumerate}
          \item Set the \code{EXE} variable with the path to the executable of the target algorithm.
          \item Set the \code{FIXED_PARAMS} if you need extra arguments in the execution line of your algorithm, 
                an example could be the time that your algorithm is required to run (\code{FIXED_PARAMS="--time 60"})
                or the number of evaluations required (\code{FIXED_PARAMS="--evaluations 10000"}).
          \item The line provided in template:
                \begin{center}
                 \code{\$EXE \$\{FIXED_PARAMS\} -i \$\{INSTANCE\} --seed \$\{SEED\} \$\{CAND_PARAMS\}}
                \end{center}
                
                Will execute the executable described in the EXE variable. You must change this line according
                to the way your algorithm is executed. In this example, the algorithm receives the instance to
                solve with the flag \code{-i} and the seed with the flag \code{--seed}. The variable
                 \code{CAND_PARAMS} adds to the command line the parameters that \irace has give for 
                 the execution.
                You are free to set the command line execution as needed, for example the instance might not need
                a flag and might need to be only the first argument:
                \begin{center}
                 \code{\$EXE \$\{INSTANCE\} \$\{FIXED_PARAMS\} --seed \$\{SEED\} \$\{CAND_PARAMS\}}
                \end{center}
                The output of your algorithm is redirected to the file defined in the \code{$STDOUT} variable
                when there is an error in the execution the output of it will be in \code{$STDERR}. The line:
                 \begin{center}
                \code{if [ -s "\${STDOUT}" ]; then}
                \end{center}
                checks if the file where the output of your algorithm was redirected exists. The example provided 
                in the template assumes that your algorithm prints in the last 
                output line the best result found (only a number). The line:
                \begin{center}
                \code{COST=\$(cat \$\{STDOUT\} | grep -e '\^~[[:space:]]*[+-]\\?[0-9]' | cut -f1)}
                \end{center}
                parses the output of your algorithm to obtain the result from the last line. The \code{target-runner}
                script must return \textbf{only} one number. In the template example the result is returned with 
                \code{echo "\$COST"} and the used files are deleted.
                
                \begin{xwarningbox}
                The \code{target-runner} script must be executable.
                \end{xwarningbox}
                
                You can test the target runner from the \aR console by performing an scenario check:
                
 <<irace_R_check2, eval=FALSE, prompt=TRUE>>=
library("irace")
scenario <- readScenario(filename="scenario.txt",
                         scenario=defaultScenario())
checkIraceScenario(scenario=scenario)
@

If you are using GNU/Linux you can also execute the check from the command-line:
 <<irace_check2,engine='bash', eval=FALSE>>=
# $IRACE_HOME is the installation directory of irace.
$IRACE_HOME/bin/irace --scenario scenario.txt --check
@
           
                If you have problems related to the \code{target-runner} script when executing \irace see 
                Section~\ref{sec:check list} for a check list to find the problems. For more information 
                about the \parameter{targetRunner} please see Section~\ref{sec:runner},
        \end{enumerate}
      
      \item \textit{Optional}: Modify the \code{target-evaluator} file. You can follow the guidelines provided for
            defining the \parameter{targetEvaluator} in Section~\ref{sec:evaluator}. 

\end{enumerate}

Once the files have been prepared you can execute \irace using the command-line or directly from the \aR console:

\begin{itemize}
\item{
\textbf{On the console}: call the command:
<<irace_cmd_exe,engine='bash', eval=FALSE>>=
cd ~/tuning/ 
$IRACE_HOME/bin/irace 
@
}
\item{
\textbf{On the \aR console}: create the \aR objects \code{scenario} and \code{parameters}, 
go to the created directory (\code{cd tuning}), open an \aR console and execute:

<<irace_R_exe, eval=FALSE, prompt=TRUE>>=
library("irace")
parameters <- readParameters("parameters.txt")
scenario <- readScenario(filename="scenario.txt",
                          scenario=defaultScenario())
irace(scenario=scenario, parameters=parameters)
@
}
\end{itemize}

This will perform one run of \irace. See the output of \code{irace --help} in the command-line or \code{irace.usage()} in \aR for quick information on 
additional \irace parameters, for more information about \irace options see Section~\ref{sec:irace options}. 

\begin{xwarningbox}
Command-line parameters override the scenario setup specified in the scenario.txt file.
\end{xwarningbox}

\subsection{Set-up example for ACOTSP}\label{sec:example}

The \ACOTSP tuning example can be found in the package installation:
\begin{center}
 \code{$IRACE_HOME/examples/acotsp}
\end{center}
Additionally, a number of example scenarios can be found in the \code{examples} folder. More 
examples of tuning scenarios can be found in the Algorithm Configuration Library (AClib):
\begin{center}
\url{http://www.aclib.net/}
\end{center}  

In this section we describe how to execute the \ACOTSP scenario, if you wish to start setting up 
your own scenario continue in the next section. For the example we assume
a GNU/Linux system but making the necessary changes in the commands and \parameter{targetRunner},
it can be executed in any system that has a \code{C} compiler.
%\MANUEL{I don't think this is true, since the target-runner script needs Bash}
To execute this scenario follow the steps
described in the following:

\begin{enumerate}
\item Create a directory for the tuning (\eg~\code{~/tuning/}) and copy the example scenario files 
located in the \code{examples} folder to the created directory: 
<<dir0,engine='bash',eval=FALSE>>=
mkdir ~/tuning
cd ~/tuning
# $IRACE_HOME is the installation directory of irace.
cp $IRACE_HOME/examples/acotsp/* ~/tuning/
@

\item Download the training instances from \url{http://iridia.ulb.ac.be/irace/} to the \code{~/tuning/} directory.
\item Create the instance directory (\eg~\code{~/tuning/Instances}) and decompress the instance files in on it.

<<instance0,engine='bash',eval=FALSE>>=
mkdir ~/tuning/Instances/
cd ~/tuning/
tar -xvf tsp-instances-training.tar.bz2 Instances/
@
\item Download the \ACOTSP software from \url{http://www.aco-metaheuristic.org/aco-code/} to the \code{~/tuning/}
directory and compile it.

<<acotsp0,engine='bash',eval=FALSE>>=
cd ~/tuning/
tar -xvf ACOTSP-1.03.tgz
cd ~/tuning/ACOTSP-1.03
make
@ 
\item Create a directory for the executable and copy it:

<<acotsp1,engine='bash',eval=FALSE>>=
mkdir ~/bin/
cp ~/tuning/ACOTSP-1.03/acotsp ~/bin/
@ 

\item Create a directory for executing the experiments and execute \irace:

<<runexample,engine='bash',eval=FALSE>>=
mkdir ~/tuning/acotsp-arena/
cd ~/tuning/
# $IRACE_HOME is the installation directory of irace.
$IRACE_HOME/bin/irace 
@ 

\item You can also execute \irace from the \aR console using:

<<runexample2,prompt=TRUE,eval=FALSE>>=
library("irace")
set.wd("~/tuning/")
parameters <- readParameters("parameters-acotsp.txt")
scenario <- readScenario(filename="scenario.txt", 
                         scenario=defaultScenario())
irace(scenario=scenario, parameters=parameters)
@ 
 
\end{enumerate}

\section{\irace scenario}
\subsection{Target algorithm parameters} \label{sec:target parameters}

The target parameters are defined by a parameter file as described in 
Section~\ref{sec:parameters file}. Optionally, when executing \irace 
from the \aR console, the parameters can be specified directly as an
\aR object (see Section~\ref{sec:parameters object}). For defining your parameters
follow the guidelines provided in the following sections.
 
\subsubsection{Parameter types}

In \irace each target parameter has an associated type which defines
the possible values it can take and the way \irace handles them
internally. Understanding the nature of the domains of the target
parameters is important to select appropriate types. The four basic
types supported by \irace are the following:

\begin{itemize}
\item \textit{Real} parameters are numerical parameters that can take
  any floating-point values within a given range. The range is
  specified as an interval `\code{(<lower bound>,<upper
    bound>)}'. This interval is closed, that is, the parameter value
  may eventually be one of the bounds. The possible values are rounded
  to a number of \emph{decimal places} specified by
  option \parameter{digits}. For example, given the default
  number of digits of $4$, the values $0.12345$ and
  $0.12341$ are both rounded to $0.1234$.
  % However, the values  $0.00001$ and $0.00005$ remain the same.

\item \textit{Integer} parameters are numerical parameters that can
  take only integer values within the given range. The range is
  specified as for real parameters. 

\item \textit{Categorical} parameters are defined by a set of possible
  values specified as `\code{(<value 1>, ..., <value n>)}'. The values
  are quoted or unquoted character strings. Empty strings and strings
  containing commas or spaces must be quoted.

\item \emph{Ordinal} parameters are defined by an \emph{ordered} set
  of possible values in the same format as for categorical
  parameters. They are handled internally as integer parameters, where
  the integers correspond to the indexes of the values.

\end{itemize}

\subsubsection{Parameter values} For each target parameter an interval
or a set of values must be defined. There is no limit for the size of
the set or the length of the interval, but keep in mind that larger
domains could increase the difficulty of the tuning task. Choose always values that you
consider relevant for the tuning. All intervals are considered as
closed intervals. 

It is possible to define parameters that will have always the same value. 
Such ``fixed'' parameters will not be tuned but their values are used 
when executing the target algorithm and they are affected by constraints 
defined on them. All fixed parameters must be defined as categorical 
parameters and have a one element set.

\subsubsection{Conditional parameters} Conditional parameters are
active only when others have certain values, this dependencies define
a hierarchical relation between parameters. For example, if the target
algorithm can select to use or not a tabu search, then only if a tabu 
search is chosen as local search the, the parameter that controls the 
length of the tabu list needs to be set.

\subsubsection{Parameter file format}\label{sec:parameters file}

For simplicity, the description of the parameters space is given as a
table. Each line of the table defines a configurable parameter:\\


\code{<name> <label> <type> <range>  [ | <condition>] } \\

where each field is defined as follows:


\begin{center}
\renewcommand{\arraystretch}{1.2}
  \begin{tabularx}{0.98\linewidth}{@{}rX}
    \code{<name>} & The name of the parameter as an unquoted
    alphanumeric string,
    for instance: `\code{ants}'.\\
    %
    \code{<label>}& A \emph{label} for this parameter. This is a
    string that will be passed together with the parameter
    to \parameter{targetRunner}. In the default \parameter{targetRunner}
    provided with the package (Section~\ref{sec:runner}), this is the
    command-line switch used to pass the value of this parameter, for
    instance `\code{"-{}-ants "}'.\\
    % The value of the parameter is concatenated \emph{without
    % separator} to the switch string when
    % invoking \parameter{hookRun}.\\
    %
    \code{{<type>}} &The type of the parameter, either
    \textit{integer}, \textit{real}, \textit{ordinal} or
    \textit{categorical}, given as a single letter: `\code{i}',
    `\code{r}', `\code{o}' or `\code{c}'. \\ 
    %
    \code{{<range>}} &The
    range or set of values of the parameter delimited by simple
    parethesis. \eg~\code{(0,1)} or \code{(a,b,c,d)}.\\ 
    %
    \code{{<condition>}}& An
    optional \emph{condition} that determines whether the parameter is
    enabled or disabled, thus making the parameter subordinate. If the
    condition evaluates to false, then no value is assigned to this
    parameter, and neither the parameter value nor the corresponding
    label are passed to \parameter{targetRunner}. The condition must be a
    valid \aR logical expression\footnote{For a quick list of \aR operators
    see: \url{https://stat.ethz.ch/R-manual/R-devel/library/base/html/Syntax.html}}. 
    The condition may contain the name
    of other parameters as long as the dependency graph does not
    contain any cycle. Otherwise, \irace will detect the cycle and
    stop with an error. \\
  \end{tabularx}
\end{center}

Figure~\ref{fig:acotsp_parameters} gives as example the parameters file 
of the ACOTSP scenario:

\begin{figure}[!ht]
  \centering
  \footnotesize
\begin{CodeInput}
# name      switch           type values    [| conditions (using R syntax)]
algorithm   "--"             c    (as,mmas,eas,ras,acs)
localsearch "--localsearch " c    (0, 1, 2, 3)
alpha       "--alpha "       r    (0.01, 5.00)
beta        "--beta "        r    (0.01, 10.00)
rho         "--rho  "        r    (0.00, 1.00)
ants        "--ants "        i    (5, 100)
nnls        "--nnls "        i    (5, 50)    | localsearch %in% c(1, 2, 3)
q0          "--q0 "          r    (0.0, 1.0) | algorithm %in% c("acs")
dlb         "--dlb "         c    (0, 1)     | localsearch %in% c(1,2,3)
rasrank     "--rasranks "    i    (1, 100)   | algorithm %in% c("ras")
elitistants "--elitistants " i    (1, 750)   | algorithm %in% c("eas")
\end{CodeInput}
\caption{Parameter file (\code{parameters.txt}) for tuning \ACOTSP.}\label{fig:acotsp_parameters}
\end{figure}

\subsubsection{Parameters R format}\label{sec:parameters object}
The target parameters are stored in an \aR~\code{list} you can obtain from the \aR console using the following command:

<<readParameters,prompt=TRUE, eval=FALSE>>=
parameters <- readParameters(file="parameters.txt")
@

See the help of the \code{readParameters} function (\code{?readParameters}) for more information. 
The structure of the parameter list that is created is as follows:
  
\begin{center}
\renewcommand{\arraystretch}{1.2}
  \begin{tabularx}{0.98\linewidth}{@{}rX}
    \code{names}        & Vector that contains the names of the parameters. \\
    \code{types}        & Vector that contains the type of each parameter 'i', 'c', 'r', 'o'. \\
    \code{switches}     & Vector that contains the switches to be used for the
    parameters on the command line. \\
    \code{domain}       & List of vectors, where each vector may contain two
    values (minimum, maximum) for real and integer parameters, or
    a set of values for categorical and ordinal parameters.\\
    \code{conditions}   & List of \aR logical expressions, with variables
   corresponding to parameter names.\\
    \code{isFixed}      & Logical vectors that specifies which parameter is fixed
   and, thus, it does not need to be tuned.\\
    \code{nbParameters} & An integer, the total number of parameters.\\
    \code{nbFixed}      & An integer, the number of parameters with a fixed value.\\
    \code{nbVariable}   & Number of variable (to be tuned) parameters.\\
  \end{tabularx}
\end{center}

The following example shows the structure of the \code{parameters} \aR object
for the \code{algorithm}, \code{ants} and \code{q0} parameters of the \ACOTSP scenario:

<<parameterlist,eval=TRUE, prompt=TRUE, size='normalsize', comment="#">>=
print(parameters)
@

\subsection{Target algorithm runner}
\label{sec:runner}

The execution of a candidate configuration on a single instance is done by means of a user-given auxiliary
program or, alternatively, a user-given \aR function. The function (or program name) is specified by the option
\parameter{targetRunner}. The \parameter{targetRunner} must return the 
evaluation of the execution unless a post-execution evaluation (\eg multi objective evaluation) is required, see Section~\ref{sec:evaluator} for details. 

\begin{xwarningbox}
 The objective of \irace is to minimize the obtained evaluations. 
 If you wish to maximize you can multiply the evaluations by \code{-1} before returning them.
\end{xwarningbox}

\subsubsection{Target runner executable program}

When \parameter{targetRunner} is an auxiliary executable program, it
is invoked for each candidate configuration, passing as arguments: \\~ \\
\code{\footnotesize <configuration\_id> <instance\_id> <seed> <instance> [<extra\_instance\_params>] <command\_line>} \\

\begin{enumerate}
  
  \item \code{configuration id} : The numeric identifier uniquely identifies a configuration.
  \item \code{instance id}: The numeric identifier uniquely identifies a pair \code{<instance, seed>}.        
  \item \code{seed}: Seed to be used for the execution.                  
  \item \code{instance}: Instance to be used for the execution.
  \item \code{extra instance parameters}: User-defined value associated to the instance.
  \item \code{command line}: Candidate configuration command line.

\end{enumerate}

The experiment list shown in Section~\ref{sec:runner fx}, would result in the following execution line:

<<target_runner_cmd, engine='bash', eval=FALSE>>=
./targetRunner 1 113 734718556 \
 /home/user/instances/tsp/2000-533.tsp --eas --localsearch 0 \
 --alpha 2.92 --beta 3.06 --rho 0.6 --ants 80 
 @

The command line is constructed by appending to each
parameter label (switch), \emph{without separator}, the value of the
parameter, following the order given in the parameter table. The
program \parameter{targetRunner} must print (only) a real number, which
corresponds to the cost measure of the candidate configuration for the
given instance. The working directory of \parameter{targetRunner} is set to
the execution directory specified by the option \parameter{execDir}. This allows the user to execute several
runs of \irace in parallel without the runs interfering with each other.

\subsubsection{Target runner R function}
\label{sec:runner fx}

When \parameter{targetRunner} is an \aR function, then it is invoked
for each candidate configuration as: 
% 
<<targetRunner,prompt=TRUE, eval=FALSE>>=
targetRunner(experiment, scenario)
@
% 
%
where \code{experiment} is a list that contains the information of
candidate and instance to execute one experiment and \code{scenario} is the scenario
list. The structure of the \code{experiment} list is as follows:

\begin{center}
\renewcommand{\arraystretch}{1.2}
  \begin{tabularx}{0.98\linewidth}{@{}rX}

   \code{id.configuration} & The numeric identifier uniquely identifies a configuration.\\
   \code{id.instance}      &  The numeric identifier uniquely identifies a pair \code{<instance, seed>}.\\
   \code{seed}             & Seed to be used for the execution.\\
   \code{configuration}    & Data frame with a column per parameter name.\\
   \code{instance}         & Instance to be used for the execution.\\
   \code{extra.params}     & User-defined value associated to the instance.\\
   \code{switches}         & Parameter switches in the order of parameters used in \code{configuration}.\\
 
  \end{tabularx}
\end{center}

The following is an example of an experiment list for the \ACOTSP scenario:

<<experimentlist,eval=TRUE,size='normalsize', prompt=TRUE,  comment="#">>=
print(experiment)
@

The function \parameter{targetRunner} must return a numerical value
corresponding to the evaluation of the candidate configuration on
the given instance. 



\subsection{Target evaluator} \label{sec:evaluator}

The evaluation of the execution of a candidate configuration on an 
instance must be returned when finalizing the \parameter{targetRunner} 
execution (See Section~\ref{sec:runner}). Nevertheless there are cases 
when the evaluation of the candidate configurations must be delayed until 
all candidate configurations in a race have been executed on a instance. 

\irace provides the option to postpone the evaluations of the candidate 
configurations by the use of a user-defined evaluation by setting the 
\parameter{targetEvaluator} parameter as either an \aR function or an 
auxiliary program. The \parameter{targetEvaluator} evaluations are executed 
when all alive candidate configurations have been executed on an instance.

\begin{xwarningbox}
When targetEvaluator is in use targetRunner must not return the evaluation
of the configuration.
\end{xwarningbox}

As an example, \parameter{targetEvaluator} may be used to dynamically find
normalization bounds for the output returned by an algorithm for each
individual instances. In this case, \parameter{targetRunner} will save the
output of the algorithm, then the first call to \parameter{targetEvaluator}
will examine the output produced by all calls to \parameter{targetRunner} for
the same instance, update the normalization bounds and return the normalized
output. Subsequent calls to \parameter{targetEvaluator} for the same instance
will simply return the normalized output.

A similar need arises when using quality measures for multi-objective
optimization algorithms, such as the hypervolume~\cite{}, which typically
require specifying reference points or sets. By
using \parameter{targetEvaluator}, it is possible to dynamically compute the
reference points or sets while \irace is running. Examples are provided at
\code{examples/hypervolume}. See also Section~\ref{sec:multi objective} for
more information on how to tune multi-objective algorithms.
 

\subsubsection{Target evaluator R function}

When \parameter{targetEvaluator} is an \aR function, then it is invoked
for each candidate configuration as: 
% 
<<targetEvaluator, prompt=TRUE, eval=FALSE>>=
targetEvaluator(experiment, num.configurations, all.conf.id, 
scenario, target.runner.call)
@
% 
%
where \code{experiment} is a list that contains the information of one 
experiment (See Section~\ref{sec:runner fx}), \code{num.configurations} 
is the number of configurations alive on the race, \code{all.conf.id} is 
the list of the alive candidates configurations ids,  \code{scenario} is 
the scenario list and \code{target.tunner.call} is the string of the 
\parameter{targetRunner} execution line. 

The function \parameter{targetEvaluator} must return a numerical value
corresponding to the cost measure of the candidate configuration on
the given instance.

\subsubsection{Target evaluator executable program}

When \parameter{targetEvaluator} is an auxiliary executable program, then it
is invoked for each candidate configuration once all the alive candidates 
have been executed in an instance. The executable receives the following arguments:

\begin{enumerate}
 \item \code{configuration id}: The numeric identifier uniquely identifies a configuration.
 \item \code{instance id}: The numeric identifier uniquely identifies a pair \code{<instance, seed>}.
 \item \code{seed}: Seed to be used for the execution. 
 \item \code{instance}: Instance to be used for the execution.
 \item \code{total candidates}: Number of alive candidates.
 \item \code{alive candidates ids}: Alive candidates ids.
\end{enumerate}

The \parameter{targetEvaluator} executable must print a numerical value
corresponding to the cost measure of the candidate configuration on
the given instance.


\subsection{Training instances}\label{sec:training}


The training instances can be specified using the options 
\parameter{trainInstancesDir} and \parameter{trainInstancesFile}. The 
default training instance directory is \textit{./Instances}, you 
can modify this directory using the \parameter{trainInstancesDir} option 
(\eg~ \code{--train-instances-dir ~/my-instances/}). A file containing 
a list of instances can be specified using the \parameter{trainInstancesFile} 
option (\eg~ \code{--train-instances-file ./instances-list.txt}). 

The format of the file is one instance per line, the first value of each 
line corresponds to the instance filename. If \parameter{trainInstancesDir} is 
provided the instance filename is considered relative to the directory specified. 
The following values in each line correspond to extra parameters to be used with 
the specific instance. The following example shows a training instance file for 
the \ACOTSP scenario:

\begin{figure}[!ht]
  \centering
\begin{CodeInput}
#Example training instances file
100/100-1_100-2.tsp --time 1
100/100-1_100-3.tsp --time 2
100/100-1_100-4.tsp --time 3
\end{CodeInput}
\caption{Training instances file for tuning \ACOTSP.}\label{fig:acotsp_training}
\end{figure}

If \code{./my-instances/} is provided as \parameter{trainInstancesDir},
\irace will assume instances are located in this directory, for example the first 
instance would be passed to \parameter{targetRunner} as \code{./my-instances/100/100-1_100-2.tsp}.
Disable the use of a directory by setting it as empty. Extra parameters are always passed 
to \parameter{targetRunner} together with the candidate configuration parameters values. 

When having instances that are not files, for example descriptive types (\eg~ functions), 
use the name and extra instance parameters to define the instance. For example:

\begin{figure}[!ht]
  \centering
\begin{CodeInput}
#Example training instances file
rosenbrock --nvar 20
rosenbrock --nvar 30
rastrigin --nvar 20
rastrigin --nvar 30
\end{CodeInput}
\caption{Training instances file example with no instance files.}\label{fig:nofile_training}
\end{figure}

Optionally when executing \irace from the \aR console you can use directly the 
\code{scenario$instances} variable. To create an instance list for the previous example use:

<<instance1, prompt=TRUE, eval=FALSE>>=
scenario$instances <- 
 c("rosenbrock", "rosenbrock", "rastrigin", "rastrigin")
scenario$instances.extra.params <- 
 c("--nvar 20", "--nvar 30", "--nvar 20", "--nvar 30")
@


The \parameter{deterministic} option activates the deterministic algorithm mode. Each instance will be
used at most once per race. Use this mode for algorithms that do not have an stochastic behavior
and therefore executing instances several times with different seeds does not make sense.
\begin{xwarningbox}
If \parameter{deterministic} is active and the number of training instances provided to \irace is less than
\parameter{firstTest} (default: 5), no statistical test will be performed on the race. 
\end{xwarningbox}

When \parameter{deterministic} is disabled \irace assigns each instance a seed once all the 
\code{<instance,seed>} pairs are used new pairs are generated with different seeds. 

The option \parameter{sampleInstances} enables the sampling of the instances, disable this
option (\code{--sample-instances 0}) if you know the order provided in the instance file is adequate 
for the tuning. 

\begin{xwarningbox}
We advise to always sample instances in order to prevent biasing the tuning due to
the instance order. 
\end{xwarningbox}



\subsection{Initial candidates} \label{sec:initial}

The scenario option \parameter{configurationsFile} allows to specify a set 
of configurations to start the execution of \irace. If the number 
of initial configurations supplied is less than the number of configurations required by \irace
in the first iteration, extra candidate configurations will be sampled uniformly.

The format of the configurations file is one configuration per line, 
and one parameter value per column. The first line must give the parameter name 
corresponding to each column (names must match those given in the parameters
file). Each configuration must satisfy the parameter conditions (\code{NA} 
should be used for those parameters that are not enabled for a given 
configuration) and, if given, the constraints described by forbidden configurations 
(Section~\ref{sec:forbidden}).

Figure~\ref{fig:acotsp_default} gives an example file that corresponds to the \ACOTSP scenario:

\begin{figure}[!ht]
  \centering
\footnotesize
\begin{CodeInput}
## Initial candidate configuration for irace
algorithm localsearch alpha beta rho  ants nnls dlb q0 rasrank elitistants
as        0           1.0   1.0  0.95 10   NA   NA  0  NA      NA
\end{CodeInput}
\caption{Initial configuration file (\code{default.txt}) for tuning \ACOTSP.}\label{fig:acotsp_default}
\end{figure}

We advise to use this feature when a default configuration of the target algorithm exists or when
different sets of good target parameters values are known. This will allow \irace to start the search 
from those parameter values and attempt to improve their performance.


\subsection{Forbidden configurations}\label{sec:forbidden}
The scenario option \parameter{forbiddenFile} allows to specify a file containing 
parameter value combinations that should not be generated during the tuning.
This option can be useful when some known combination of values could
cause the target algorithm to crash or when it is know that some parameter
combinations do no produce satisfactory results.

The format of the forbidden configurations file is one constraint per line. 
Each constraint is a logical expression (in R syntax), for a quick list
of \aR logical operators see:
\begin{center}
 \url{https://stat.ethz.ch/R-manual/R-devel/library/base/html/Syntax.html}
\end{center}
The parameters are called by the parameter name set in the \parameter{parameterFile} described
in Section~\ref{sec:target parameters}.

If a parameter configuration is generated that makes the logical expression evaluate 
to \code{TRUE}, then the configuration is considered forbidden and is discarded. Figure~\ref{fig:acotsp_forbidden} 
shows an example file that corresponds to the \ACOTSP scenario:

\begin{figure}[!ht]
  \centering
\begin{CodeInput}
## Examples of valid logical operators are:
## ==  !=  >=  <=  >  <  &  |  !  %in%
(alpha == 0.0) & (beta == 0.0)
\end{CodeInput}
\caption{Forbidden configurations file (\code{forbidden.txt}) for tuning \ACOTSP.}\label{fig:acotsp_forbidden}
\end{figure}

\begin{xwarningbox}
Note that if initial configuration are provided (Section~\ref{sec:initial}), they must also comply with the
constraints defined in \parameter{forbiddenFile}.
\end{xwarningbox}

\section{Parallelization}\label{sec:parallel}
A single run of \irace can be done much faster by executing the calls
to \parameter{targetRunner} (the runs of the target algorithm) in
parallel. There are three ways to parallelize a single run of \irace:

\begin{itemize}
\item \textbf{Parallel processes}: The option \parameter{parallel} allows
  executing in parallel, within a single computer, the calls
  to \parameter{targetRunner}, by means of the \pkg{parallel} \aR package. For
  example, adding \code{--parallel N} to the command line of \irace will launch
  in parallel up to $N$ calls of the target algorithm.

\item \textbf{MPI}: By enabling the option \parameter{mpi}, calls
  to \parameter{targetRunner} will be executed in parallel by using the message
  passing interface (MPI) protocol (requires the \pkg{Rmpi} \aR package). In
  this case, the option \parameter{parallel} controls the number of slave nodes
  used by \irace. For example, adding \code{--mpi 1 --parallel N} to the
  command-line will create $N$ slaves + 1 master, and execute up to $N$ calls of
  \parameter{targetRunner} in parallel.

   The user is responsible for setting up the required MPI environment.  MPI is
   commonly available in computing clusters and requires launching \irace in
   some particular way. An example script for using MPI mode in an SGE cluster
   is given at \code{$IRACE_HOME/examples/mpi/}.
       
 \item \textbf{SGE cluster}: This mode uses the commands \code{qsub} and
   \code{qstat} often found in Sun Grid Engine (SGE) and compatible
   clusters. The command \code{qsub} must return a message that contains the
   string: \code{Your job JOBID}, where \code{JOBID} is a unique identifier for
   the job submitted.  The command \code{qstat -j JOBID} must return nonzero if
   JOBID has finished its execution, and zero otherwise.
   
   Enabling the option \parameter{sgeCluster} (\code{--sge-cluster 1}) will
   launch as many calls of \parameter{targetRunner} as possible and use \code{qstat}
   to wait for cluster jobs. The user \underline{must} call \code{qsub} from
   \parameter{targetRunner} with the appropriate settings for their cluster,
   otherwise \parameter{targetRunner} will not submit jobs to the cluster. In this
   mode, \irace must run in the submission node, and hence, \code{qsub} should
   not be used to invoke \irace itself.  Moreover, the use of a separate
   \parameter{targetEvaluator} script is required to parse the results of
   \parameter{targetRunner} and return them to \irace. See the examples in
    \code{$IRACE_HOME/examples/sge-cluster/}.

  \item \parameter{targetRunnerParallel}: This option allows users to fully
    control the parallelization of \parameter{targetRunner}. Its value must be
    an \aR function that will be invoked by \irace as follows:
   
   <<targetRunnerParallel,prompt=FALSE, eval=FALSE>>=
     targetRunnerParallel(experiments, targetRunner, scenario)
   @
   %
   where \code{experiments} is a list that contains elements with the
   information of configurations and instances to be executed (see
   Section~\ref{sec:runner} for a description), \parameter{targetRunner} is the
   \parameter{targetRunner} script or function and \code{scenario} is the scenario
   list. The \parameter{targetRunnerParallel} function must execute the
   \parameter{targetRunner} using the given experiments and scenario provided, and
   return a list of the same length as \code{experiments} containing the output
   of each call to \parameter{targetRunner}.
     

\end{itemize}

\section{Testing of configurations}\label{sec:testing}

Once the tuning process is finished \irace commonly returns a set of configurations, out of which
one is the best regarding the mean. These configurations have been found to be not statistically 
different and therefore they all could be appropriate to use. To further investigate the quality 
of this configurations \irace offers the possibility of executing the testing of these 
configurations on a test instance set at the end of the execution. Even more, the testing can also be
performed including the best configuration of each iteration. 

The options \parameter{testNbElites} and \parameter{testIterationElites} allow to set 
a testing of the best configurations found after the \irace execution has been completed.
The test instance set can be specified by the options \parameter{testInstancesDir} and \parameter{testInstancesFile} 
if using a directory or text file, or by setting the variable \code{scenario$testInstances} directly from the \aR console. 
For the testing each instance is assigned a different seed in the same way that is done for the tuning. 
To set the testing instances follow the same guidelines as for the training instances (see Section~\ref{sec:training}). 

There are two types of testing:
\begin{itemize}
\item \textbf{Final elite configurations testing}: \parameter{testNbElites} 
indicates the number of elite configurations to be tested, if 
the number of elite configurations is less than the value provided for \parameter{testNbElites}, 
then the number of elite configurations is used as \parameter{testNbElites}.

\item \textbf{Iteration elite configurations testing}: \parameter{testIterationElites} 
enables the testing of the best configuration found at each iteration.

\end{itemize}

If the the testing options are specified when launching \irace the, testing 
will be performed immediately after the tuning. The testing can be executed 
later using the following \aR command:

<<testing_r, prompt=TRUE, eval=FALSE>>=
testing.main(logFile="~/tuning/irace.Rdata")
@

This line will load the \irace results found in the generated \parameter{logFile} 
file to perform the testing. The testing results will be saved in the \irace 
log file specified in \code{scenario$logFile} in the \code{iraceResults$testing} 
\aR object. The structure of the object is described in Section~\ref{sec:output r}
for examples on how to analyse the data or the testing and the \irace data see
Section~\ref{sec:analysis}.

\section{Recovering \irace runs}\label{sec:rec}

Problems like power cuts, hardware malfunction or the need to use computational power 
for other tasks may occur during the execution of the \irace causing that the tuning is 
not executed completely. \irace saves at the end of each iteration an \aR data file that 
not only contains the information of the tuning progress (See Section~\ref{sec:output r}) 
but also internal information that allows to recover an incomplete execution.

To recover an \irace execution use the \parameter{recoveryFile} option and specify the \aR data log
file to be used. \irace will continue the execution from the last saved iteration. The state 
of the random generator is saved and loaded, therefore, as long as the execution is continued
in the same machine, the obtained results will be exactly as executing \irace in one go.
You can specify the \parameter{recoveryFile} from the command-line or from the scenario file, 
and execute \irace as described in Section~\ref{sec:execution}. For example from the command-line use:

<<lauch_reco, engine="bash", eval=FALSE>>=
irace --recovery-file "./irace-backup.Rdata" 
@

When an execution is recovered, the \irace log will be saved on the file specified with 
the \parameter{logFile} option. 

\begin{xwarningbox}
You must define a different location for the \parameter{logFile} and the \parameter{recoveryFile}. 
Before executing the recovery please change the name of the saved \aR data file.
\end{xwarningbox}  

When recovery is done you can modify some \irace options from the command-line or 
from the scenario file.

%\LESLIE{Actually, there other variables we allow to change...what we shoudl say about this?}

\begin{itemize}
\item \parameter{execDir}
\item \parameter{logFile}
\item \parameter{debugLevel}
\item \parameter{parallel}
\item \parameter{loadBalancing}
\item \parameter{mpi}
\item \parameter{sgeCluster}
\end{itemize}

It is not possible (and in most cases not correct) to change the scenario options, given that the 
previous results can become invalid. However there are some cases in which this options must be changed, 
for example, if you have instances that are files, it might be the case that the instances are not 
available in the same location. To change the location of them you should modify directly the \aR data file, 
please be careful not to change the order of the instances, because this would make the results obtained by 
\irace invalid. To change the instances path open the \aR console and use:

<<change_recover, prompt=TRUE, eval=FALSE>>=
load ("~/tuning/irace.Rdata")
new.path <- "~/experiments/tuning/instances/"
iraceResults$scenario$instances <- 
   paste (new.path, 
         basename(iraceResults$scenario$instances), 
         sep="")
save (iraceResults, file="~/tuning/irace.Rdata")
@

This example can also can be applied to the target execution files \parameter{targetRunner} and \parameter{targetEvaluator}.
\begin{xwarningbox}
Before changing any other option directly in the \aR data log, please consider carefully the
effect the change will cause in the tuning. For questions contact us in the \irace group (Section\ref{sec:contact}).
\end{xwarningbox}

\section{Output and results}
During the execution of \irace a text output with the progress of 
the tuning will be shown in the standard output. Additionally, after each 
iteration an \aR data file is produced (\parameter{logFile} option), this file contains 
the partial results of the \irace execution.

\subsection{Text output}\label{sec:output text}
Figure~\ref{fig:output} shows the output of \irace until the first iteration. This 
is an execution of the elitist \irace version using the \ACOTSP benchmark with 1000 
evaluations as budget.  

Note that \irace gives a warning because has found a file with the default scenario file 
name, this is just a notice. Initially, general information about the selected \irace
options is printed:
\begin{itemize}
 \item \code{nbIterations} indicates the minimum number of iterations \irace has calculated 
       for the scenario. Depending on the development of the tuning the final iterations that
       are executed can be more.
  \item \code{minNbSurvival} indicates the minimum number of alive configurations that
       are required to continue a race. When less configurations are alive the race is 
      stopped and a new iteration begins.
  \item \code{nbParameters} is the number of parameters of the scenario.
  \item \code{seed} is the number that was used to initialize the random number generator in \irace.
  \item \code{confidence level} is the confidence level of the statistical test.
  \item \code{budget} is the total number of evaluations available for the tuning.
  \item \code{mu} is a value used for calculating the minimum number of iterations.
  \item \code{deterministic} indicates if the target algorithm has been marked as deterministic.  
\end{itemize}
 

\begin{figure}[!ht]
  \centering
  \footnotesize
\begin{CodeInput}
*******************************************************************************
Warning: A default scenario file './scenario.txt' has been found and will be read
# 2016-05-02 19:24:50 CEST: Elitist race
# Elitist instances: 1
# Elitist limit: 2

# 2016-05-02 19:24:50 CEST: Initialization
# nbIterations: 5
# minNbSurvival: 5
# nbParameters: 11
# seed: 1234
# confidence level: 0.95
# budget: 1000
# mu: 5
# deterministic: FALSE

# 2016-05-02 19:24:50 CEST: Iteration 1 of 5
# experimentsUsedSoFar: 0
# remainingBudget: 1000
# currentBudget: 200
# nbConfigurations: 33
  Markers:
     x No test is performed.
     - The test is performed and some configurations are discarded.
     = The test is performed but no configuration is discarded.
     ! The test is performed and configurations could be discarded but elite 
       configurations are preserved.
                                                                   
+-+---------+------+-----+------------+-----------+--------+-----+----+------+
| | Instance| Alive| Best|   Mean best| Exp so far|  W time|  rho|KenW|  Qvar|
+-+---------+------+-----+------------+-----------+--------+-----+----+------+
|x|        1|    33|   15| 23268924.00|         33|00:01:55|   NA|  NA|    NA|
|x|        2|    33|    8| 23185736.50|         66|00:01:53|+0.97|0.99|0.0025|
|x|        3|    33|    8| 23239054.33|         99|00:01:56|+0.96|0.97|0.0030|
|x|        4|    33|    8| 23168442.50|        132|00:01:55|+0.96|0.97|0.0027|
|-|        5|     3|    8| 23222299.80|        165|00:01:56|-0.05|0.16|0.7109|
+-+---------+------+-----+------------+-----------+--------+-----+----+------+
Best configuration:           8    mean value:     23222299.80
Description of the best configuration:
  .ID. algorithm localsearch  alpha   beta    rho ants nnls     q0 dlb rasrank 
8    8       acs           1 3.8157 8.5915 0.4141   59   10 0.5812   1      NA 
  elitistants .PARENT.
           NA       NA

# 2016-05-02 19:34:27 CEST: Elite configurations:
   algorithm localsearch  alpha   beta    rho ants nnls     q0 dlb rasrank elitistants
8        acs           1 3.8157 8.5915 0.4141   59   10 0.5812   1      NA          NA
18      mmas           2 3.1134 7.3864 0.4623   60   32     NA   1      NA          NA
15       ras           3 2.5838 6.5086 0.5082   42    6     NA   0      90          NA
\end{CodeInput}
\caption{Sample text output of \irace.}\label{fig:output}
\end{figure}

In each iteration information about the progress of the execution printed as follows:
\begin{itemize}
  \item \code{experimentsUsedSoFar} is the number of experiments from the total budget
        has been used until the actual iteration.
  \item \code{remainingBudget} is the number of evaluations that have not been used yet.
  \item \code{currentBudget} is the number of evaluations \irace has allocated to the
        current iteration.
  \item \code{nbConfigurations} is the number of configurations \irace will use in the
        current iteration. On the first iteration this number of configurations include 
        the initial configurations provided and in later iterations includes the elite 
        candidates of the previous iterations.
\end{itemize}

After the iteration information a table is shows the progress of the iteration execution.
Each row of the table gives information about the execution of an instance in the race.
The first column contains a symbol that describes the results or non application of the 
statistical test:
 
In each iteration is initially printed information about the progress of the execution:
\begin{itemize}
\item \code{|x|} : No statistical test was performed for this instance. To adjust in which 
      instances of a race statistical tests are performed see \irace options \parameter{firstTest} 
      and \parameter{eachTest} in Section~\ref{sec:irace options}.
\item \code{|-|} : Statistical test performed and configurations have been discarded, to know how 
      many configurations have been discarded see the table column \code{Alive}.
\item \code{|=|} : Statistical test performed and no configurations have veen discarded. 
      This means \irace needs more information to identify the best configurations.
\item \code{|!|}: This indicator exists only for the elitist version of \irace, indicates that
      the statistical test was performed and some elite configurations show bad performance and
      could be discarded but they are kept given the elitist \irace discarding rules. See \irace
      option \parameter{elitist} in Section~\ref{sec:irace options} for more information.
\end{itemize}

The \code{instance} column gives the number of \code{<instance, seed>} pair executed, this number 
corresponds to the index of the list found in \code{scenario$instancesList}, see Section~\ref{sec:output r} 
for more information.

The \code{Alive} column gives the number of configurations that have not been discarded after 
the statistical test was performed. The column \code{Best} gives the id of the best 
configuration according to the experiments performed so far in the race (includes previous instances).
The \code{Mean best} column gives the mean of the best configuration across all the instances executed so 
far in the race. The \code{Exp so far} gives the number of evaluations performed so far.
The \code{W time} column gives the waiting time to execute all the configurations in the current instance.

The columns \code{rho} and \code{KenW} give the values of the Spearman's rho and the Kendall concordance 
coefficient of the configurations across the instances executed so far. The \code{Qvar} gives the variance
measure across the instances.
%LESLIE{CITE PAPER OF HOLGER}
Use \code{rho}, \code{KenW} and \code{Qvar} to analyze how 
consistent is the performance of the configurations across the instances. Note that this values are only 
valid for the instances that were already executed in the iteration. Values close to 1 for \code{rho}
and \code{KenW} and values close to 0 for the \code{Qvar} indicate that the performance is consistent 
and therefore the scenario is homogeneous. For heterogeneous we provide advice in Section~\ref{sec:het}.

Finally \irace outputs the best configuration found and a list of the elite configurations. The elite 
configurations are configurations that did not show statistical difference during the race, they are 
printed according to their mean performance on the executed instances. 


\subsection{Data file output}\label{sec:output r}
The \aR data file created by \irace (\parameter{logFile}) contains an object called 
\code{iraceResults}, you can load this data in the \aR console by:

<<load_rdata, prompt=TRUE, eval=FALSE>>=
load("irace-output.Rdata")
@

The \code{iraceResults} object is a list, the elements of a list can be accessed in \aR
by using the \code{\$} or \code{[[]]} operators:

<<show_version, prompt=TRUE, eval=TRUE, comment="#">>=
iraceResults$irace.version
iraceResults[["irace.version"]]
@

The \code{iraceResults} list contains the following elements:


\begin{itemize}
\item \code{scenario}: The scenario \aR object containing the \irace options 
  used for the execution. See Section~\ref{sec:irace options} and the help 
  of the \pkg{irace} package, open an \aR console and type: \code{?defaultScenario}. 
  See Section~\ref{sec:irace options} for more information.
  
\item \code{parameters}: The parameters \aR object containing the description of
  the target algorithm parameters. See Section~\ref{sec:target parameters}.
  
\item \code{allConfigurations}: The target algorithm configurations generated by 
  \irace. This object is a \code{data frame}, each row is a candidate 
   configuration, the first column (\code{.ID.}) indicates the internal identifier of the 
   configuration, the following columns correspond to the parameter values, each column named as 
   the parameter name specified in the parameter object. The final column (\code{.PARENT.}) is the identifier 
   of the configuration from which model the actual configuration was sampled.
   
<<show_configurations, prompt=TRUE, eval=TRUE, comment="#">>=
head(iraceResults$allConfigurations) 
@

\item \code{allElites}: A list that contains one element per iteration, each element contains 
  the internal identifier of the elite candidate configurations of the corresponding iteration 
  (identifiers correspond to \code{allConfigurations$.ID.}). 
  
<<show_idelites, prompt=TRUE, eval=TRUE, comment="#">>=
print(iraceResults$allElites) 
@

The configuration are ordered by mean performance, that is, the id of the best configuration corresponds
to the first id. To obtain the values of the parameters of all elite configuration found by \irace use:

<<get_elites, prompt=TRUE, eval=TRUE, comment="#">>=
getFinalElites(irace.logFile="irace-output.Rdata", n=0)
@
  
\item \code{iterationElites}: A vector containing the best candidate configuration internal
  identifier of each iteration. The best configuration found corresponds to the last one 
  of this vector. 
<<show_iditelites, prompt=TRUE, eval=TRUE, comment="#">>=
print(iraceResults$iterationElites) 
@  
  
Obtain the full configuration with:
  
<<get_elite, prompt=TRUE, eval=TRUE, comment="#">>=
last <- length(iraceResults$iterationElites)
id <- iraceResults$iterationElites[last]
getConfigurationById(irace.logFile="irace-output.Rdata", 
                     ids=id)
@

\item \code{experiments}: A matrix with configurations as columns and instances 
as rows. Column names correspond to the internal identifier of the configuration 
(\code{allConfigurations$.ID.}), to obtain the experiment results of a particular 
configuration use:

<<get_experiments, prompt=TRUE, eval=TRUE, comment="#">>=
# As an example, we use the best configuration found
best.config <- getFinalElites(iraceResults=iraceResults, 
                              n=1)
id <- best.config$.ID.
# Obtain the configurations using the identifier 
# of the best configuration
all.exp <- iraceResults$experiments[,as.character(id)]
all.exp[!is.na(all.exp)]
@

When a configuration was not executed on an instance there is a \code{NA} value in 
the corresponding matrix cell. A configuration is not executed on an instance for three 
different reasons: 1) because it was not created yet when the instance was used 
(only for the non elitist \irace) or 2) because it was discarded by the statistical test 
or 3) the race was terminated before the instance could reach the execution of the instance.

The row names correspond to the identifier of the \code{<instance, seed>} pairs 
defined in \code{scenario$instancesList}. To obtain the instance and seed used 
for a particular experiment use:

<<get_instance_seed, prompt=TRUE, eval=TRUE, comment="#">>=
# As an example, we get seed and instance of the experiments
# of the best candidate.
# Get index of the instances
pair.id <- names(all.exp[!is.na(all.exp)])
index <- 
    iraceResults$scenario$instancesList[pair.id,"instance"]
# Obtain the instance names
iraceResults$scenario$instances[index]
# Get the seeds
iraceResults$scenario$instancesList[index,"seed"]
@
\item \code{experimentLog}: A matrix with columns: 
\begin{center}
\code{<iteration, instance, configuration>}. 
\end{center}
This matrix contains the log of all the experiments that \irace 
performs during its execution. The instance column refers to the index of the 
\code{scenario$instancesList} data frame.

\item \code{softRestart}: A logical vector that indicates if a soft restart was 
performed on each iteration. If \code{FALSE}, then no soft restart was performed.
For info about soft restart see Section~\ref{sec:irace options}.

\item \code{state}: A list that contains the state of \irace, the recovery 
(Section~\ref{sec:rec}) is done using the information contained in this object. The
probabilistic model of the last elite configurations can be found here doing:

<<get_model, prompt=TRUE, eval=TRUE, comment="#">>=
# As an example, we get the model probabilities for the
# localsearch parameter.
iraceResults$state$model["localsearch"]
# The order of the probailities corresponds to:
iraceResults$parameters$domain$localsearch
@

The example shows a list that has one element per elite configuration (id as 
element name). In this case \code{localsearch} is a categorical parameter, 
it has a probability per each value.


\item \code{testing}: A list that contains the testing results.
The list contains the following elements:
  \begin{itemize}
    \item \code{experiments}: Matrix of experiments in the same format as the
      tuning \code{experiment} matrix. The column names indicate the candidate 
      configuration identifier and the row names contain the name of the instances.
<<get_test_exp, prompt=TRUE, eval=TRUE, comment="#">>=
# Get the experiments of the testing
iraceResults$testing$experiments
@
      
    \item \code{seeds}: The seeds used for the experiments, each seed corresponds to
      each instance in the rows of the test \code{experiments} matrix.
<<get_test_seeds, prompt=TRUE, eval=TRUE, comment="#">>=
# Get the experiments of the testing
iraceResults$testing$seeds
@

In the example instance \code{1000-1.tsp} is executed with seed \code{1815573416}.
%%\LESLIE{Change this with the new output.}

  \end{itemize}
 
\end{itemize}

\subsection{Analysis of results}\label{sec:analysis}
The best configurations provided by \irace are configurations that where found to be not 
statistically different. The configurations are reported in average 
performance order, that is, the best by mean configuration is reported first. 

If testing is performed you can further analyze the resulting best configurations 
by performing statistical tests in R or just plotting the results:

<<plot_test, prompt=TRUE, eval=TRUE, comment="#">>=
results <- iraceResults$testing$experiments
# Wilcoxon paired test
conf <- gl(ncol(results), #number of configurations
           nrow(results), #number of instances
           labels=colnames(results))
pairwise.wilcox.test (as.vector(results), 
                      conf, 
                      paired=TRUE,
                      p.adj = "bonf")
# Plot the results
boxplot (iraceResults$testing$experiments, 
         ylab="solution quality", 
         xlab="configuration id")

@

%%FIXME: should we add something like this?
%The Kendall concordance coefficient (\code{W}) and the Spearman's rho can be 
%applied over data that has the characteristics of the data obtained in the testing, 
%that is a full matrix where all configurations are executed in all instances. \code{W} 
%can show if the configurations tested have an homogeneous performance on the used instances 
%set. If evidence of an heterogeneous scenario found we recommend to make some adjustments 
%in the \irace options as described in Section~\ref{sec:}

%<<conc, prompt=TRUE, eval=TRUE, comment="#">>=
%irace:::concordance(iraceResults$testing$experiments)

%@
%   

During the tuning \irace iteratively updates sampling models for the 
parameters focusing in the best areas of the parameter search space. The 
frequency of the sampled configurations can provide insight on the parameter 
search space, we provide a function that allows to create plots that show the 
frequency of the sampling of a set of configurations. The following example
plots the frequency of the parameters sampled during all the \irace execution:

<<freq, prompt=TRUE, eval=TRUE, comment="#">>=
parameterFrequency(iraceResults$allConfigurations,
                   iraceResults$parameters) 

@

For more information of this function please see the \aR help, type in the 
\aR console: \code{?parameterFrequency}.


Using parallel coordinates plots is possible to analyze how the parameters
interact with each other. The following example shows how to create a parallel
coordinate plot of the candidates of the last two iterations of \irace.

<<parcord, prompt=TRUE, eval=TRUE, comment="#">>=
# Get last iteration number
last <- length(iraceResults$iterationElites)
lasts <- c(last-1, last)
# Get last iterations candidates
conf <- getConfigurationByIteration(iraceResults = iraceResults, 
                                    iterations = lasts) 
parallelCoordinatesPlot (conf, 
                         iraceResults$parameters,
                         param_names=c("algorithm",
                                       "alpha",
                                       "beta",
                                       "rho",
                                       "q0"),
                         hierarchy=FALSE)

@
For more information of this function please see the \aR help, type 
in the \aR console: (\code{?parallelCoordinatesPlot}).


\section{Advanced topics}
\subsection{Multi Objective tuning}\label{sec:multi objective}
\irace performs the automatic configuration of an algorithm optimizing only one objective
that can be solution quality, computation time or any other and that is obtained by \irace 
through the \parameter{targetRunner}.

If you wish to tune your algorithm with \irace for more than one objective there are two alternatives:

\begin{itemize}
\item Aggregate the objectives in one resulting number.
\item Use the hypervolume indicator for evaluating the quality of the configurations.
\end{itemize}

The first option is simple, it requires to devise a formula that can aggregate the objectives 
in a way that balances the importance of all of them. This might not be an easy task in some 
scenarios, using a more adequate indicator like the hypervolume is strongly advised.

For using the hypervolume as evaluation \irace needs to postpone the evaluation of the
configurations in an instance until all of the executions have been completed. Once 
the executions are finalized the evaluation starts by obtaining reference points~
%\LESLIE{I dont think they are called like this no?} 
for each objective from the configuration results. This points are used to define the pareto front and the hypervolume of each configuration 
is calculated and the tuning process continues normally. 
%\LESLIE{hahaha I dont really know what Im writting :D...}

For setting up the multi objective tuning you must not return the evaluation of the experiment
when finalizing the execution of \parameter{targetRunner} (see Section~\ref{sec:runner}) and specify 
a \parameter{targetEvaluator} in which the reference points are obtained and the hypervolume is calculated. 
For more information about defininf a \parameter{targetEvaluator} see Section~\ref{sec:evaluator}
For the hypervolume calculation we suggest the following implementation:

\begin{center}
\url{http://lopez-ibanez.eu/hypervolume}
\end{center}

Examples of a multi objective tuning using the hypervolume can be found in the templates:

\begin{center}
\code{$IRACE_HOME/examples/hypervolume}\\
\code{$IRACE_HOME/examples/moaco}
\end{center}   

\subsection{Tuning computation time}

\irace was developed primarily for tuning solution quality, to use \irace for tuning 
computation time the execution time must be returned as result by the \parameter{targetRunner}. 
Nevertheless other tuners available have better methods to handle the execution
of the target algorithm by using ``adaptive capping''. When tuning for optimizing the computation 
time of an algorithm we recommend to try out \code{ParamILS} and \code{SMAC} tuners in the following links:

\begin{center}
\url{http://www.cs.ubc.ca/labs/beta/Projects/ParamILS/}\\
\url{http://www.cs.ubc.ca/labs/beta/Projects/SMAC/}
\end{center}

\subsection{Heterogeneous scenarios}
\label{sec:het}

We classify an scenario as homogeneous when the target algorithm has a consistent
performance regarding the instances that is, good configurations are probably good 
for all the instances. On the contrary, for heterogeneous scenarios the target algorithm
has an inconsistent performance on different instances, that is, some configurations 
are good for one or a subset of instances while are very bad for another subset of instances.

If you know your scenario has heterogeneous characteristics, the first question you should 
ask yourself is if the tuning objective is to find configurations that are good for all 
instances. If this is not the case, then separate executions of \irace, one per 
instance type, is the best choice.
 
If finding a good configuration for all the instances is the objective then we recommend 
to always sample the instances initially (option \parameter{sampleInstances}) unless you 
provide an instance order that does not bias the search. For example, assume you have an scenario 
that has two kinds of instances, if the ten first instances belong to only one class, 
the search will be biased to obtain configurations that are good for that instances. 
The best order in this case would be to intercalate different types of instances 
to avoid bias.

Another advice is to increase the number of instances executed per iteration, 
an heterogeneous scenario will need to gather more information about the different instances
before discarding configurations. Use the option \parameter{elitistInstances} when the elitist
\irace version (option \parameter{elitist}) is used to increase the number of new instances 
executed in each iteration. When using the non elitist \irace version you can indirectly 
increase the number of instances by increase the \parameter{firstTest} option. 

When executing \irace you can analyze the homogeneity of the scenario by observing the 
results of the Kendall W and Spearman's rho in the text output of \irace. 
See Section~\ref{sec:output text} for more information.

\subsection{Choosing the statistical test} 
\label{sec:stat test}
The statistical test identifies statistically bad performing configurations that \irace
can discard of the race in order to save budget. The criterion which is used to assess
the quality of the configurations might have effect on the tuning results.

\irace provides two kinds of statistical tests, both test have different characteristics
that could be beneficial for certain scenarios:
\begin{itemize}
\item Friedman test (\code{F-test}): This test uses the ranking of the configurations
to analyze the difference between the performance. This makes the test suitable for 
scenarios where the numerical results and their scale are not significant to assess 
the quality of the configurations. 
For example if the results in different instances have high numerical differences
and evaluating the performance of the configurations using, for example, the mean 
could be deceiving.
We recommend to use the \code{F-test} (default) always when tuning for solution
quality and whenever the best performing algorithm must solve as good as possible
all the instances.
\item Student's t-test (\code{t-test}): This test uses the mean performance of the 
configurations to analyze the difference between the configurations. This makes the test 
suitable for scenarios where the differences between values obtained for different 
instances are relevant to assess good configurations. 
We recommend using t-test when tuning for computation time, whenever the obtained configurations 
must solve the instances in the best averaged time. 
\end{itemize}

Using the option \parameter{confidence} is possible to set the statistical significance of 
the test. Increase the value of \parameter{confidence} to have a more strict statistical test.
Keep in mind that a strict test will require more budget to identify which configurations 
perform worse. While a less strict test discards configurations quickly by requiring less
data against them and therefore it has more probability of discarding good configurations.
  

\subsection{Complex parameters}
Some parameters may have complex dependencies, we advice to always try to define the 
parameters in the way that is most suitable for the tuning objective. For example, when tuning 
a branch and bound algorithm one may have the following parameters:

\begin{itemize}
\item branching (\code{b}): This parameter can take the values \code{\{0,1,2,3\}}, 0 indicates no branching will be used
      and the rest are different types of branching.
\item stabilization (\code{s}): This parameter can take the values \code{\{0,1,2,3,4,5,6,7,8,9,10\}}, of which for \code{b=0}
      only \code{\{0,1,2,3,4,5\}} are relevant.
\end{itemize}

In this case is not possible to describe the parameter space defining only two
parameters for \irace. An extra parameter must be introduced as follows: \\

  \begin{CodeInput}
# <name> <label> <type> <range>                  [ | <condition>]
b         "-b "   c      (0,1,2,3)
s1        "-s "   c      (0,1,2,3,4,5)            | b == "0"
s2        "-s "   c      (0,1,2,3,4,5,6,7,8,9,10) | b != "0" 
  \end{CodeInput}

Parameters whose values depend on the value of other parameters also could
be described using extra parameters or changing the parameters and processing them in
the \parameter{targetRunner}. For example the following parameters:

\begin{itemize}
\item Population size (\code{p}): This parameter can take the integer values \code{[2,100]}.
\item Selection size (\code{s}): This parameter can take as maximum the population size, that is \code{[1,p]}.
\end{itemize}

In this case is possible to describe the parameters as a percentage as described below. 
The parameter values must be processed in the \parameter{targetRunner}. For example if 
\code{p=0.5} then we must transform this number to the interval \code{[2,100]} giving us 
that \code{p=51} then \code{s=0.3} will be transformed as \code{s=15}.

  \begin{CodeInput}
# <name> <label> <type> <range>    
p        "-p "   r      (0.0,1.0)
s        "-s "   r      (0.1,1.0)            
  \end{CodeInput}
  
More complex value dependencies could be also expressed by mixing extra parameters and 
transformations. Keep in mind that the \parameter{targetRunner} can also process the parameters.
You can also split parameters and join them in the \parameter{targetRunner}, for example assume the 
following parameters:

  \begin{CodeInput}
# <name> <label> <type> <range>  
m        "-m "   i      (1,250)
e        "-e "   r      (0.0,2.0)            
  \end{CodeInput}

These parameters could be part of one parameter that has a multiplier and an exponent that has 
to be passed to your target algorithm as \code{"--strength }$m\cdot 10^{e}$\code{"}. \parameter{targetRunner} can
join the extra parameters \code{e} and \code{m} and provide them in the correct format.
 
\subsection{Unreliable target algorithms}

There are some situations in which the target algorithm may fail to execute
correctly.  This could be due to system problems or bugs for which no fix is
available or fixing them is impossible because there is no access to the source
code.

The \irace option \parameter{targetRunnerRetries} indicates the number of times a
\parameter{targetRunner} execution is repeated if it fails. Use this option if you 
know new repetitions could be successful. 

When the program consistently fails using a particular set of configurations 
and repeating the execution will cause always the program to crash, you can use
the \parameter{forbiddenFile} option to specify the configurations that must be 
avoided. On the other hand, if you do not know which configurations cause the 
problems, we advise you to handle this in the \parameter{targetRunner} script, when the program
crashes you can use a penalty evaluation (very big number for minimization) that 
will allow \irace to discard the configuration based on that result. Adjust the 
penalty according to your objective and the results you consider appropriate, 
for example, if a configuration crashes for an instance you might still consider 
it as a good configuration if it gives very good results for other instances.


\section{\irace options} \label{sec:irace options}

Most of the \irace options can be specified by command line using a flag, 
by setting them in the \irace scenario file using the option name or 
by directly setting them in the scenario \aR object. This section describes
the \irace options that can be specified by the user:\\

%\LESLIE{Improve this comments} 

\subsection{General options}
\begin{description}
\defparameter[-s]{scenarioFile}{--scenario}{./scenario.txt} %
  File that contains the scenario setup and other irace settings. All the options listed in this section 
  can be included in this file. See \code{$IRACE_HOME/templates/} for an example.
  
\defparameter{debugLevel}{--debug-level}{0} %
  Level of information to display in the text output of \irace. A value of 0 silences all debug messages. 
  Higher values provide more verbose debug messages. To see details about the text output of \irace see 
  Section~\ref{sec:output text}.
  
\defparameter{seed}{--seed}{NA} % 
  Seed to initiallize the random number generator, the seed must be a positive integer, if the seed is 
  \code{NA} a random seed will be used.
  
\defparameter{execDir}{--exec-dir}{./} %
  Directory where the target algorithm executions will be performed. The default execDir is the current directory.
  \begin{xwarningbox}
   \irace will not attempt to create the execution directory so it must exist before calling \irace. 
 \end{xwarningbox}
     
\defparameter[-l]{logFile}{--log-file}{./irace.Rdata} %  
  File to save tuning results as an R dataset, the provided path must be either an absolute path 
  or a relative to \parameter{execDir}. See Section\~ref{sec:output r} for details on the format of the 
  R dataset.
  
\end{description}  

\subsection{Elitist \irace}
\begin{description}
\defparameter{elitist}{--elitist}{1} %
  Enable/disable elitist \irace. \\
  
  In the \textbf{elitist \code{irace} version} elite configurations cannot be discarded from the race until the 
  new configurations have executed the same instances as the elite configurations.  
  
  The race begins with a number of initial instances for which any configuration in race
  have been executed, this number of instances can be defined with the option \parameter{elitistInstances}.
  Once the new instances have been executed the instances executed in previous iterations are executed,
  elite configurations have already results for most of these instances and therefore do not need to be 
  executed. Finally when the ``previous instances'' are executed new instances are executed. 
  
  The statistical tests can be performed at any moment during the race according to the setting of the
  options \parameter{firstTest} and \parameter{eachTest}, the elitist rule forbids to discard elite configurations,
  even if the show bad performance, until the last ``previous instance'' has been executed.  
  
  The \textbf{non-elitist \irace version} can discard the elite configurations from the race at any time.
  Instances are not re-used from an iteration to another, new instances are always executed unless the 
  \parameter{deterministic} option is active, for which the instances are repeated if all instances have been used.    
  
\defparameter{elitistInstances}{--elitist-instances}{1} %
  Number of new instances to add to execution list before ``previous instances'' in elitist \irace.
  \begin{xwarningbox}
  If \parameter{deterministic} is \code{TRUE} then the number of \parameter{elitistInstances} will be reduced or 
  set to \code{0} in case no more instances are available.
  \end{xwarningbox}
  
\defparameter{elitistLimit}{--elitist-limit}{2} %
  Limit for the elitist race, when the number statistical test performed without successful elimination 
  reaches \parameter{elitistLimit} the race will be inmediately stopped. This limit has effect after all 
  ``previous instances'' have been executed. Use 0 for disable the limit.
\end{description} 
 

\subsection{Internal \irace options}
\begin{description}
\defparameter{sampleInstances}{--sample-instances}{1} %
  Enable/disable the sampleing of the the training instances. If the option \parameter{sampleInstaces} is disabled,
  the instances are used in the order provided in the \parameter{trainInstancesFile} or in the order that
  are read from the \parameter{trainInstancesDir} when\parameter{trainInstancesFile} is not provided. For more
  information about training instances see Section~\ref{sec:training}.
  
\defparameter{nbIterations}{--iterations}{0} %
  Number of iterations to be executed. By default \irace calculates the number of iterations based on the
  scenario as described as follows where $\Nparam$ is the number of non fixed parameters to be tuned. 
  We recommend to use the default value.
  
  \begin{equation}
  \Niter = \lfloor 2 + \log_{2}\Nparam \rfloor
  \end{equation}
  
\defparameter{nbExperimentsPerIteration}{--experiments-per-iteration} {0} %
  Number of experiments to execute per iteration. By default \irace calculates the number of experiments per 
  iteration based on the scenario as follows, where $\Budgetj$ is the budget for iteration $j$, $\Budget$ is the total
  tuning budget (\parameter{maxExperiments}), $\Bused$ is the used budget and $\Niter$ is maximum between the planned number of 
   iterations (\parameter{nbIterations}) and the current iteration ($j$). We recommend to use the default value.
  \begin{equation}
    \Budgetj = \dfrac{(\Budget - \Bused)}{ (\Niter -\iter + 1)}
  \end{equation}
  
\defparameter{nbConfigurations}{--num-configurations}{0} %
  The number of configurations that should be sampled and evaluated at each iteration. By default \irace 
  calculates the number of configurations per iteration based on the scenario as follows, where $\Ncand[\iter]$ is the
  number of configurations that will be used in iteration $j$, $\Budgetj$ is the budget for iteration $j$ and $\mu$ is the \irace 
  option \parameter{mu}. We recommend to use the default value.
  \begin{equation}
  \Ncand[\iter] = \lfloor \dfrac{\Budgetj} { (\mu + \min(5,\iter))}\rfloor
  \end{equation}
  
\defparameter{mu}{--mu}{5} %
  This value is used to determine the number of configurations to be sampled and evaluated at each iteration.
  
  
\defparameter{minNbSurvival}{--min-survival}{0} %
  The minimum number of configurations needed to continue the execution of an iteration.
  
\defparameter{softRestart}{--soft-restart}{1} %
  Enable/disable the soft restart strategy that avoids premature convergence of the probabilistic model. 
  When a sampled configuration is \textit{highly similar} to its parent configuration the probabilistic model
  of all the configurations is soft restarted. The similarity of categorical and ordered parameters is given
  by the hamming distance, the option \parameter{softRestartThreshold} defines the similatiry of numerical parameters.

  
\defparameter{softRestartThreshold}{--soft-restart-threshold}{NA} %
  Soft restart threshold value for numerical parameters. If \code{NA}, it computed as $10^{-digits}$, where 
  \parameter{digits} corresponds to the \irace option explained in this section.

\end{description} 

\subsection{Target algorithm parameters}
\begin{description}

\defparameter[-p]{parameterFile}{--param-file}{./parameters.txt} %
  File that contains the description of the parameters of the target algorithm. See section~\ref{sec:target parameters}.
  
\defparameter{digits}{--digits}{4} %
  Number of decimal places to be considered for the real parameters.
  
\defparameter{forbiddenFile}{--forbidden-file}{} %
  File containing a list of logical expressions that cannot be true for any evaluated configuration. If
  empty or \code{NULL}, no forbidden rules are considered. See Section~\ref{sec:forbidden} for more information.
  
\end{description} 

\subsection{Target algorithm execution}
\begin{description}

\defparameter{targetRunner}{--target-runner}{./target-runner} %
  This option defines a script or an \aR function that launches the program to be tuned for a particular 
  experiment (configuration + instance). See Section~\ref{sec:runner} for details.
  
\defparameter{targetRunnerRetries}{--target-runner-retries}{0} %
  Number of times to retry a call to \parameter{targetRunner} if the call failed.
  
\defparameter{targetRunnerData}{}{NULL} %
Optional data passed to \parameter{targetRunner}. This is ignored by the default \parameter{targetRunner} function, but it may be used by custom \parameter{targetRunner} functions to pass persistent data around.

\defparameter{targetRunnerParallel}{}{NULL} %
 Optional \aR function to provide custom parallelization of \parameter{targetRunner}. See Section~\ref{sec:parallel} 
 for more information.

\defparameter{targetEvaluator}{--target-evaluator}{""} %
  Optional script or \aR function that evaluates an experiment (configuration + instance), that is. 
  The evaluation must consist of a numeric value. See Section~\ref{sec:evaluator} for details.

\defparameter{deterministic}{--deterministic}{0} %
  Enable/disable deterministic algorithm mode. If the target algorithm is deterministic, configurations will be evaluated only once per instance. See Section~\ref{sec:training} for more information.
  \begin{xwarningbox}
  Note that if the number of instances provided is less than the value
  specified for the option \parameter{firstTest}, no statistical test will be performed. 
  \end{xwarningbox}

\defparameter{parallel}{--parallel}{0} %
  Number of calls of the \parameter{targetRunner} to execute in parallel. A value of 0 means disabled. For more information 
  on parallelization see Section~\ref{sec:parallel}. 
  
\defparameter{loadBalancing}{--load-balancing}{1} %
  Enable/disable load-balancing when executing experiments in parallel. Load-balancing makes better use of computing 
  resources, but increases communication overhead. If this overhead is large, disabling load-balancing may be faster.
  See Section~\ref{sec:parallel}.
  
\defparameter{mpi}{--mpi}{0} 
  Enable/disable MPI. Use \pkg{Rmpi} to execute the \parameter{targetRunner} in parallel. When \parameter{mpi} is 
  enabled, the option \parameter{parallel} is the number of slaves. See Section~\ref{sec:parallel}.
  
\defparameter{sgeCluster}{--sge-cluster}{0} 
  Enable/disable SGE cluster mode. Use qstat to wait for cluster jobs to finish (\parameter{targetRunner} must
   invoke qsub). See Section~\ref{sec:parallel}.
   
 %\LESLIE{I have no clue how to set up this... Manuel?}

\end{description} 

\subsection{Initial configurations}
\begin{description}
\defparameter{configurationsFile}{--configurations-file}{} %
  File containing a list of initial configurations. If empty or \code{NULL} \irace will not use initial 
  configurations. See section~\ref{sec:initial}.
  
  \begin{xwarningbox}
    The provided configurations must not violate the constraints described in \parameter{parameterFile}
    and \parameter{forbiddenFile}.
  \end{xwarningbox}
\end{description} 


\subsection{Training instances}
\begin{description}
\defparameter{trainInstancesDir}{--train-instances-dir}{./Instances} %
  Directory where tuning instances are located; either absolute path or relative to current directory. See Section~\ref{sec:training}.
  
\defparameter{trainInstancesFile}{--train-instances-file}{} %
  File containing a list of instances and optionally additional parameters for them. See Section~\ref{sec:training}.
  \begin{xwarningbox}
  If \parameter{trainInstancesDir} is specified the path contained in \parameter{trainInstancesFile} must be relative to the directory. For having 
  the absolute path or for defining instances that are not files set \code{trainInstancesDir=""}.
\end{xwarningbox}
\end{description} 

\subsection{Tuning budget}
\begin{description}
\defparameter{maxExperiments}{--max-experiments}{1000}\\
  The maximum number of runs (invocations of \parameter{targetRunner}) that will be performed. It determines the maximum budget 
  of experiments for the tuning.
\end{description}
  
\subsection{Statistical test}
\begin{description}
\defparameter{testType}{--test-type}{F-test} %
  Specifies the statistical test type: 
  \begin{itemize}
    \item \code{F-test} (Friedman test)
    \item \code{t-test} (pairwise t-tests with no correction)
    \item \code{t-test-bonferroni} (t-test with Bonferroni\'s correction for multiple comparisons) 
    \item \code{t-test-holm} (t-test with Holm\'s correction for multiple comparisons).
  \end{itemize}
  See Section~\ref{sec:stat test} to have more information about how to choose the statistical test.
  
\defparameter{firstTest}{--first-test}{5} %
  Specifies how many instances are executed before the first elimination test. 
  \begin{xwarningbox}%
   The value of \parameter{firstTest} must be a multiple of \parameter{eachTest}.
  \end{xwarningbox}
  
\defparameter{eachTest}{--each-test}{1} %
  Specifies how many instances are executed between elimination tests.
  
\defparameter{confidence}{--confidence}{0.95}\\ 
  Confidence level for the elimination test.

\end{description} 

\subsection{Recovery}
\label{sec:recovery}

\begin{description}     
\defparameter{recoveryFile}{--recovery-file}{""}  %
  Previously saved \irace log file that should be used to recover the execution of irace, 
  either absolute path or relative to the current directory. If empty or \code{NULL}, recovery is not performed. 
  For more details about recovery see Section~\ref{sec:recovery}.\\

\end{description}

\subsection{Testing}
\begin{description}  
\defparameter{testNbElites}{--test-num-elites}{1} %
  Number of elite configurations returned by irace that will be tested if test instances are provided. For more information
  about the testing, see Section~\ref{sec:testing}.
  
\defparameter{testIterationElites}{--test-iteration-elites}{0} %
  Enable/disable testing the elite configurations found at each iteration.

\defparameter{testInstancesDir}{--test-instance-dir}{} %
  Directory where testing instances are located, either absolute or relative to current directory.
  
\defparameter{testInstancesFile}{--test-instance-file}{} %
  File containing a list of test instances and optionally additional parameters for them.

\end{description}

\section{FAQ}

\subsection{Is \irace minimizing or maximizing the output of my algorithm?}

        By default, \irace considers that the value returned by \parameter{targetRunner} (or by
        \parameter{targetEvaluator}, if used) should be \underline{minimized}. In case of a maximization
        problem, one can simply multiply the value by -1 before returning it to
        irace. This is done, for example, when maximizing the hypervolume (see the last
        lines in \code{$IRACE_HOME/examples/hypervolume/target-evaluator}).
        

     \subsection{Is it possible to configure a MATLAB algorithm with \irace?}

     Definitely. There are two main ways to achieve this:
     \begin{enumerate}
       \item{ Edit the \parameter{targetRunner} script to call MATLAB in a non-interactive
            way. See the MATLAB documentation, or the following links\footnote{\url{http://stackoverflow.com/questions/1518072/suppress-start-message-of-matlab}\\ \url{http://stackoverflow.com/questions/4611195/how-to-call-matlab-from-command-line-and-print-to-stdout-before-exiting}}. You would need to pass the parameter received by \parameter{targetRunner} to your MATLAB script: \url{http://www.mathworks.nl/support/solutions/en/data/1-1BS5S/?solution=1-1BS5S}. There is a minimal example in:
            \begin{center}
            \code{$IRACE_HOME/examples/matlab/}.
            \end{center}    
        }
       \item{ Call MATLAB code directly from \aR using the
            \pkg{R.matlab} package (\url{http://cran.r-project.org/package=R.matlab}). This
            is a better option if you are experienced in \aR. Define \parameter{targetRunner} as
            an \aR function instead of a path to a script. The function should
            call your MATLAB code with appropriate parameters.
       }
     \end{enumerate}

  \subsection{My program works perfectly on its own, but not when running under \irace. Is irace broken?}

     Every time this was reported, it was a difficult-to-reproduce bug in
     the program, not in \irace.  We recommend that in \parameter{targetRunner}, you use
     \code{valgrind} to run your program. That is, if you program is called like:

    <<faq1,engine='bash', eval=FALSE>>=
    $EXE ${FIXED_PARAMS} -i $INSTANCE ${CAND_PARAMS} \
     1> ${STDOUT} 2> ${STDERR}
    @
    then replace that line with:

   <<faq2,engine='bash', eval=FALSE>>=
   valgrind --error-exitcode=1 $EXE ${FIXED_PARAMS} \ 
    -i $INSTANCE ${CAND_PARAMS} 1> ${STDOUT} 2> ${STDERR}
   @
  If there are bugs in your program, they will appear in \code{${STDERR}}, thus do not delete those files. 
 

  \subsection{My program may be buggy and run into an infinite loop. Is it possible to set a maximum timeout? }
  
    We are not aware of any way to achieve this using \aR. However, in
    GNU/Linux, it is easy to implement by using the \code{timeout} command in  
    \code{targetRunner} when invoking your program.
        
%FIXME: complete this section
%\section{Known problems}

\section{Resources and contact information} \label{sec:contact}
More information of the package can be found on the \irace webpage:\\
\begin{center} \url{http://iridia.ulb.ac.be/irace/}. \end{center}

For questions and suggestions please contact the development team through the mailing list:
\begin{center} \href{mailto:irace@iridia.ulb.ac.be}{irace@iridia.ulb.ac.be} \end{center}
or the \irace package Google group:\\
\begin{center} \url{https://groups.google.com/d/forum/irace-package} \end{center}

\section{Acknowledgements} 

We would like to thank all the people that directly or indirectly have
colaborated in the development and improvement of \irace.

\begin{itemize}
%% MANUEL: I don't think we should mention ourselves.
%% \item Mauro Birattari
%% \item Thomas St\"uzle
%% \item Manuel L\'opez-Ib\'a\~nez
%% \item J\'er\'emie Dubois-Lacoste
%% \item Leslie P\'erez C\'aceres
\item Prasanna Balaprakash
\item Zhi (Eric) Yuan
\item Franco Mascia
\item Alberto Franzin
\item Anthony Antoun
\end{itemize}

\newpage 

\begin{appendices}

\section{R installation} \label{sec:installation}

In this section we give a quick \aR installation guide that will work in 
most cases. The official instructions are available at 
\url{http://cran.r-project.org/doc/manuals/r-release/R-admin.html}

\subsection{GNU/Linux}
You should install \aR from your package manager. On a Debian/Ubuntu system 
it will be something like:
<<R_linux_install,engine='bash',eval=FALSE>>=
sudo apt-get install r-base
@
Once \aR is installed, you can launch \aR from the Terminal and from the \aR prompt 
install the \irace package (see Section~\ref{sec:irace install}).


\subsection{OS X}

You can install \aR directly from a CRAN mirror\footnote{Belgian CRAN mirror: 
\url{http://cran.freestatistics.org/bin/macosx/}}. Alternatively, if you use 
homebrew, you can just brew the \aR formula from the science tap (unfortunately 
it does not come already bottled so you need to have Xcode\footnote{Xcode download 
webpage: \url{https://developer.apple.com/xcode/download/}} installed to compile it):
<<R_OS_install,engine='bash',eval=FALSE>>=
brew tap homebrew/science
brew install r
@
Once \aR is installed, you can launch \aR from the Terminal (or from your Applications), 
and from the \aR prompt install the \irace package (see Section~\ref{sec:irace install}).

\subsection{Windows}

You can install \aR from a CRAN mirror\footnote{Belgian CRAN mirror:
  \url{http://cran.freestatistics.org/bin/windows/}}. We recommend that you
install \aR on a filesystem path without spaces, special characters or long
names, such as \path{C:\R}. Once \aR is installed, you can launch the \aR
console and install the \irace package from it (see Section~\ref{sec:irace
  install}).


\section{TargetRunner script check list} \label{sec:check list}

When the \parameter{targetRunner} script is not running properly can be difficult to detect where 
the problem is. The more your script provide descriptive errors, the more easy will be to debug. If you are 
using temporary files to redirect the output of your algorithm check that these are created 
properly. We recommend you to follow the structure of the example file (\code{target-runner}) 
provided in \code{\$IRACE_HOME/templates}. The following examples are based in a file with 
that characteristics.

When you have problems with the \parameter{targetRunner} you will see an error on the \irace output
that says that the execution the \parameter{targetRunner} was not successful. 

Follow this list to detect where the problem is:

\begin{enumerate}[leftmargin=0cm]

\item Make sure that your \code{targetRunner script} is the specified location. If you see an error as follows:\\

\code{Error: == irace == run program runner '~/tuning/target-runner' does not exist}\\

This means that \irace is not finding the script file. Check that the file is in the path specified by the error.

\item Make sure that your \code{targetRunner} script is an executable if you see an error as follows:\\

\code{Error: == irace == run program runner '~/tuning/target-runner' is a directory, not a file}\\

or\\

\code{Error: == irace == run program runner '~/tuning/target-runner' is not executable}\\

This means that your \code{targetRunner} is not an executable file, in the first case the script
is a folder and therefore there must be a problem with the name of the script. For the second case
you must make the file an executable, in GNU/Linux you can do:

<<perm,engine='bash', eval=FALSE>>=
cd ~/tuning/
chmod +x target-runner
@

\item Make sure that your executable is in the location described in the script 
(variable \code{EXE} for the templates example). If you see an error like as follows 
this is your problem:\\

\code{
Error: == irace == running command ''~/tuning/target-runner' \\
1 8 676651103 ~/tuning/Instances/1000-16.tsp --ras \\
--localsearch 2 --alpha 4.03 --beta 1.89 --rho  0.02 --ants 37 \\
--nnls 48 --dlb 0 --rasranks 15 2>\&1' had status 1 \\ \\
== irace == The call to target.runner.default was:\\
~/tuning/target-runner 1 8 676651103 ~/tuning/Instances/1000-16.tsp  \\
--ras --localsearch 2 --alpha 4.03 --beta 1.89 --rho  0.02 \\
--ants 37 --nnls 48 --dlb 0 --rasranks 15\\ \\
== irace == The output was:\\
Tue May  3 19:00:37 UTC 2016: error: ~/bin/acotsp: not found \\
or not executable (pwd: ~/tuning/acotsp-arena)
}\\

For testing your script you can copy the line of execution and execute it directly 
in the command-line, in this case the line is:\\

\code{
~/tuning/target-runner 1 8 676651103 ~/tuning/Instances/1000-16.tsp  --ras 
 --localsearch 2 --alpha 4.03 --beta 1.89 --rho  0.02 --ants 37 --nnls 48  
 --dlb 0 --rasranks 15}\\

This line executes the \code{targetRunner} script as \irace does, the output of this 
script must be only one number.


\item Check that your \code{targetRunner} script is actually returning one number as 
output. If you see an error as following this is your problem:\\

\code{
Error: == irace == The output of '~/tuning/target-runner \\
1 25 365157769 ~/tuning/Instances/1000-31.tsp --ras \\
--localsearch 1 --alpha 0.26  --beta 6.95 --rho  0.69 \\
--ants 56 --nnls 10 --dlb 0 --rasranks 7' is not numeric!\\ \\
== irace == The output was:\\
Solution: 24479793
}\\


For testing your script you can copy the line of execution and execute it directly 
in the in the command-line, in this case is:\\

\code{
~/tuning/target-runner 1 25 365157769 ~/tuning/Instances/1000-31.tsp
 --ras --localsearch 1 --alpha 0.26 --beta 6.95 --rho  0.69 --ants 56 
 --nnls 10 --dlb 0 --rasranks 7}\\

This line executes the \code{targetRunner} script as \irace does, the output of this 
script must be only one number. In this example the output of the script is 
``\code{Solution: 24479793}'', that means that the regular expression used to obtain the result
from the algorithm output file must be checked. 

\item Check that your \code{targetRunner} script is creating the output files for your algorithm. 
If you see an error as follows:\\

\code{
== irace == The output was: Tue May  3 19:41:40 UTC 2016: \\
error: c1-9.stdout: No such file or directory}\\

It means that the output file of the execution of your algorithm has not been 
created (check permissions) or has been deleted before the result can be read.



\item Other errors can produce the follwing output:\\

\code{
== irace == The output was: Tue May  3 19:49:06 UTC 2016: \\
error: c1-23.stdout: Output is not a number\\}\\

This might be due that your \code{targetRunner} script is not executing your 
algorithm correctly. To further investigate comment the line that eliminates the 
temporary files where the output of your algorithm is redirected:\\

\code{rm -f "\$\{STDOUT\}" "\$\{STDERR\}"}\\

Execute the \code{targetRunner} command-line the error provides and search
in your execution directory the files that are created. Check the \code{.stderr}
file for errors and the \code{.stdout} file to see the output your algorithm produces.
 


\end{enumerate}

\section{Glossary}

\begin{enumerate}
\item Parameter tuning: Process of searching good settings for the parameters of an 
         algorithm under a particular tuning scenario (instances, execution time, etc.).
\item Scenario: Settings of a tuning scenario, these settings include the algorithm to be tuned (target), 
         budget for the execution of the target algorithm (execution time, evaluations, iterations, etc.),
          set of problem instances  and all the information that is required to perform the tuning.
\item Target algorithm: algorithm whose parameters will be tuned.
\item Target parameter: parameter of the target algorithm that will be tuned.
\item \irace option: configurable option of \irace. 
\item Elite configurations: best configurations found from whose probabilistic 
      models new configurations are sampled for the next iteration. All elite
      configurations are also included in the next iteration.
\end{enumerate}

\end{appendices}

\end{document}
